{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fd695a3-0dcd-4a7d-9528-022ff9fc574f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "role=sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d9c48d-5478-4d3f-8b38-0cfa083d1df8",
   "metadata": {},
   "source": [
    "The SageMaker Pytorch estimator can take python script as well as shell scripts as entrypoints. So you can you can configure the accelerate launch command in your bash script and pass it as an entrypoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b722f8c5-edfc-4b35-856d-e27245f6cc7e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sagemaker.image_uris:image_uri is not presented, retrieving image_uri based on instance_type, framework etc.\n",
      "INFO:sagemaker:Creating training-job with name: accelerate-launcher-shell-2024-06-07-04-25-01-285\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-06-07 04:25:02 Starting - Starting the training job...\n",
      "2024-06-07 04:25:17 Downloading - Downloading the training image\n",
      "2024-06-07 04:25:17 Training - Training image download completed. Training in progress.\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2024-06-07 04:25:17,918 sagemaker-training-toolkit INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2024-06-07 04:25:17,976 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-06-07 04:25:17,988 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2024-06-07 04:25:17,990 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2024-06-07 04:25:19,781 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-06-07 04:25:19,860 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-06-07 04:25:20,245 sagemaker-training-toolkit INFO     No Neurons detected (normal if no neurons installed)\u001b[0m\n",
      "\u001b[34m2024-06-07 04:25:20,258 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {},\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"current_instance_group\": \"homogeneousCluster\",\n",
      "    \"current_instance_group_hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"current_instance_type\": \"ml.p3.16xlarge\",\n",
      "    \"distribution_hosts\": [],\n",
      "    \"distribution_instance_groups\": [],\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {},\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {},\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"instance_groups\": [\n",
      "        \"homogeneousCluster\"\n",
      "    ],\n",
      "    \"instance_groups_dict\": {\n",
      "        \"homogeneousCluster\": {\n",
      "            \"instance_group_name\": \"homogeneousCluster\",\n",
      "            \"instance_type\": \"ml.p3.16xlarge\",\n",
      "            \"hosts\": [\n",
      "                \"algo-1\"\n",
      "            ]\n",
      "        }\n",
      "    },\n",
      "    \"is_hetero\": false,\n",
      "    \"is_master\": true,\n",
      "    \"is_modelparallel_enabled\": null,\n",
      "    \"is_smddpmprun_installed\": false,\n",
      "    \"is_smddprun_installed\": true,\n",
      "    \"job_name\": \"accelerate-launcher-shell-2024-06-07-04-25-01-285\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-259508681668/accelerate-launcher-shell-2024-06-07-04-25-01-285/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"launch_shell.sh\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 64,\n",
      "    \"num_gpus\": 8,\n",
      "    \"num_neurons\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.p3.16xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.p3.16xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"launch_shell.sh\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=launch_shell.sh\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.16xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.16xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_TYPE=ml.p3.16xlarge\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP=homogeneousCluster\u001b[0m\n",
      "\u001b[34mSM_CURRENT_INSTANCE_GROUP_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS=[\"homogeneousCluster\"]\u001b[0m\n",
      "\u001b[34mSM_INSTANCE_GROUPS_DICT={\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.16xlarge\"}}\u001b[0m\n",
      "\u001b[34mSM_DISTRIBUTION_INSTANCE_GROUPS=[]\u001b[0m\n",
      "\u001b[34mSM_IS_HETERO=false\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=launch_shell.sh\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=64\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=8\u001b[0m\n",
      "\u001b[34mSM_NUM_NEURONS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-259508681668/accelerate-launcher-shell-2024-06-07-04-25-01-285/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{},\"current_host\":\"algo-1\",\"current_instance_group\":\"homogeneousCluster\",\"current_instance_group_hosts\":[\"algo-1\"],\"current_instance_type\":\"ml.p3.16xlarge\",\"distribution_hosts\":[],\"distribution_instance_groups\":[],\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{},\"input_dir\":\"/opt/ml/input\",\"instance_groups\":[\"homogeneousCluster\"],\"instance_groups_dict\":{\"homogeneousCluster\":{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.16xlarge\"}},\"is_hetero\":false,\"is_master\":true,\"is_modelparallel_enabled\":null,\"is_smddpmprun_installed\":false,\"is_smddprun_installed\":true,\"job_name\":\"accelerate-launcher-shell-2024-06-07-04-25-01-285\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-259508681668/accelerate-launcher-shell-2024-06-07-04-25-01-285/source/sourcedir.tar.gz\",\"module_name\":\"launch_shell.sh\",\"network_interface_name\":\"eth0\",\"num_cpus\":64,\"num_gpus\":8,\"num_neurons\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.p3.16xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.p3.16xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"launch_shell.sh\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/opt/conda/bin:/opt/conda/lib/python310.zip:/opt/conda/lib/python3.10:/opt/conda/lib/python3.10/lib-dynload:/opt/conda/lib/python3.10/site-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/bin/sh -c \"./launch_shell.sh \"\u001b[0m\n",
      "\u001b[34m2024-06-07 04:25:20,287 sagemaker-training-toolkit INFO     Exceptions not imported for SageMaker TF as Tensorflow is not installed.\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: accelerate>0.3 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (0.22.0)\u001b[0m\n",
      "\u001b[34mCollecting evaluate (from -r requirements.txt (line 2))\u001b[0m\n",
      "\u001b[34mDownloading evaluate-0.4.2-py3-none-any.whl.metadata (9.3 kB)\u001b[0m\n",
      "\u001b[34mCollecting datasets==2.3.2 (from -r requirements.txt (line 3))\u001b[0m\n",
      "\u001b[34mDownloading datasets-2.3.2-py3-none-any.whl.metadata (20 kB)\u001b[0m\n",
      "\u001b[34mCollecting nltk (from -r requirements.txt (line 4))\u001b[0m\n",
      "\u001b[34mDownloading nltk-3.8.1-py3-none-any.whl.metadata (2.8 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: deepspeed in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 5)) (0.6.1+1ea3d4b)\u001b[0m\n",
      "\u001b[34mCollecting sentencepiece!=0.1.92 (from -r requirements.txt (line 6))\u001b[0m\n",
      "\u001b[34mDownloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.7 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 7)) (3.20.3)\u001b[0m\n",
      "\u001b[34mCollecting sacrebleu>=1.4.12 (from -r requirements.txt (line 8))\u001b[0m\n",
      "\u001b[34mDownloading sacrebleu-2.4.2-py3-none-any.whl.metadata (58 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 58.0/58.0 kB 8.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mCollecting py7zr (from -r requirements.txt (line 10))\u001b[0m\n",
      "\u001b[34mDownloading py7zr-0.21.0-py3-none-any.whl.metadata (17 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: torch>=1.3 in /opt/conda/lib/python3.10/site-packages (from -r requirements.txt (line 11)) (2.0.1)\u001b[0m\n",
      "\u001b[34mCollecting transformers==4.22.1 (from -r requirements.txt (line 12))\u001b[0m\n",
      "\u001b[34mDownloading transformers-4.22.1-py3-none-any.whl.metadata (84 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 84.5/84.5 kB 14.0 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets==2.3.2->-r requirements.txt (line 3)) (1.26.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyarrow>=6.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.3.2->-r requirements.txt (line 3)) (14.0.1)\u001b[0m\n",
      "\u001b[34mCollecting dill<0.3.6 (from datasets==2.3.2->-r requirements.txt (line 3))\u001b[0m\n",
      "\u001b[34mDownloading dill-0.3.5.1-py2.py3-none-any.whl.metadata (9.7 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets==2.3.2->-r requirements.txt (line 3)) (2.1.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.3.2->-r requirements.txt (line 3)) (2.31.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets==2.3.2->-r requirements.txt (line 3)) (4.65.0)\u001b[0m\n",
      "\u001b[34mCollecting xxhash (from datasets==2.3.2->-r requirements.txt (line 3))\u001b[0m\n",
      "\u001b[34mDownloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets==2.3.2->-r requirements.txt (line 3)) (0.70.15)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->datasets==2.3.2->-r requirements.txt (line 3)) (2023.10.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets==2.3.2->-r requirements.txt (line 3)) (3.9.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from datasets==2.3.2->-r requirements.txt (line 3)) (0.19.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets==2.3.2->-r requirements.txt (line 3)) (23.2)\u001b[0m\n",
      "\u001b[34mCollecting responses<0.19 (from datasets==2.3.2->-r requirements.txt (line 3))\u001b[0m\n",
      "\u001b[34mDownloading responses-0.18.0-py3-none-any.whl.metadata (29 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers==4.22.1->-r requirements.txt (line 12)) (3.13.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers==4.22.1->-r requirements.txt (line 12)) (6.0.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers==4.22.1->-r requirements.txt (line 12)) (2023.10.3)\u001b[0m\n",
      "\u001b[34mCollecting tokenizers!=0.11.3,<0.13,>=0.11.1 (from transformers==4.22.1->-r requirements.txt (line 12))\u001b[0m\n",
      "\u001b[34mDownloading tokenizers-0.12.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (6.5 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate>0.3->-r requirements.txt (line 1)) (5.9.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: click in /opt/conda/lib/python3.10/site-packages (from nltk->-r requirements.txt (line 4)) (8.1.7)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: joblib in /opt/conda/lib/python3.10/site-packages (from nltk->-r requirements.txt (line 4)) (1.3.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: hjson in /opt/conda/lib/python3.10/site-packages (from deepspeed->-r requirements.txt (line 5)) (3.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: ninja in /opt/conda/lib/python3.10/site-packages (from deepspeed->-r requirements.txt (line 5)) (1.11.1.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: py-cpuinfo in /opt/conda/lib/python3.10/site-packages (from deepspeed->-r requirements.txt (line 5)) (9.0.0)\u001b[0m\n",
      "\u001b[34mCollecting portalocker (from sacrebleu>=1.4.12->-r requirements.txt (line 8))\u001b[0m\n",
      "\u001b[34mDownloading portalocker-2.8.2-py3-none-any.whl.metadata (8.5 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tabulate>=0.8.9 in /opt/conda/lib/python3.10/site-packages (from sacrebleu>=1.4.12->-r requirements.txt (line 8)) (0.9.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from sacrebleu>=1.4.12->-r requirements.txt (line 8)) (0.4.4)\u001b[0m\n",
      "\u001b[34mCollecting lxml (from sacrebleu>=1.4.12->-r requirements.txt (line 8))\u001b[0m\n",
      "\u001b[34mDownloading lxml-5.2.2-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.4 kB)\u001b[0m\n",
      "\u001b[34mCollecting texttable (from py7zr->-r requirements.txt (line 10))\u001b[0m\n",
      "\u001b[34mDownloading texttable-1.7.0-py2.py3-none-any.whl.metadata (9.8 kB)\u001b[0m\n",
      "\u001b[34mCollecting pycryptodomex>=3.16.0 (from py7zr->-r requirements.txt (line 10))\u001b[0m\n",
      "\u001b[34mDownloading pycryptodomex-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\u001b[0m\n",
      "\u001b[34mCollecting pyzstd>=0.15.9 (from py7zr->-r requirements.txt (line 10))\u001b[0m\n",
      "\u001b[34mDownloading pyzstd-0.16.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.4 kB)\u001b[0m\n",
      "\u001b[34mCollecting pyppmd<1.2.0,>=1.1.0 (from py7zr->-r requirements.txt (line 10))\u001b[0m\n",
      "\u001b[34mDownloading pyppmd-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.7 kB)\u001b[0m\n",
      "\u001b[34mCollecting pybcj<1.1.0,>=1.0.0 (from py7zr->-r requirements.txt (line 10))\u001b[0m\n",
      "\u001b[34mDownloading pybcj-1.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\u001b[0m\n",
      "\u001b[34mCollecting multivolumefile>=0.2.3 (from py7zr->-r requirements.txt (line 10))\u001b[0m\n",
      "\u001b[34mDownloading multivolumefile-0.2.3-py3-none-any.whl.metadata (6.3 kB)\u001b[0m\n",
      "\u001b[34mCollecting inflate64<1.1.0,>=1.0.0 (from py7zr->-r requirements.txt (line 10))\u001b[0m\n",
      "\u001b[34mDownloading inflate64-1.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: brotli>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from py7zr->-r requirements.txt (line 10)) (1.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch>=1.3->-r requirements.txt (line 11)) (4.8.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.3->-r requirements.txt (line 11)) (1.12)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.3->-r requirements.txt (line 11)) (3.2.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.3->-r requirements.txt (line 11)) (3.1.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.3.2->-r requirements.txt (line 3)) (1.3.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.3.2->-r requirements.txt (line 3)) (23.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.3.2->-r requirements.txt (line 3)) (1.4.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.3.2->-r requirements.txt (line 3)) (6.0.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.3.2->-r requirements.txt (line 3)) (1.9.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets==2.3.2->-r requirements.txt (line 3)) (4.0.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.3.2->-r requirements.txt (line 3)) (3.1.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.3.2->-r requirements.txt (line 3)) (3.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.3.2->-r requirements.txt (line 3)) (1.26.18)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets==2.3.2->-r requirements.txt (line 3)) (2023.11.17)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.3->-r requirements.txt (line 11)) (2.1.3)\u001b[0m\n",
      "\u001b[34mINFO: pip is looking at multiple versions of multiprocess to determine which version is compatible with other requirements. This could take a while.\u001b[0m\n",
      "\u001b[34mCollecting multiprocess (from datasets==2.3.2->-r requirements.txt (line 3))\u001b[0m\n",
      "\u001b[34mDownloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\u001b[0m\n",
      "\u001b[34mDownloading multiprocess-0.70.14-py310-none-any.whl.metadata (6.6 kB)\u001b[0m\n",
      "\u001b[34mDownloading multiprocess-0.70.13-py310-none-any.whl.metadata (6.8 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.3.2->-r requirements.txt (line 3)) (2.8.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.3.2->-r requirements.txt (line 3)) (2023.3.post1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets==2.3.2->-r requirements.txt (line 3)) (2023.3)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.3->-r requirements.txt (line 11)) (1.3.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets==2.3.2->-r requirements.txt (line 3)) (1.16.0)\u001b[0m\n",
      "\u001b[34mDownloading datasets-2.3.2-py3-none-any.whl (362 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 362.3/362.3 kB 42.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading transformers-4.22.1-py3-none-any.whl (4.9 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 4.9/4.9 MB 91.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading evaluate-0.4.2-py3-none-any.whl (84 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 84.1/84.1 kB 13.3 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading nltk-3.8.1-py3-none-any.whl (1.5 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.5/1.5 MB 89.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 1.3/1.3 MB 83.4 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading sacrebleu-2.4.2-py3-none-any.whl (106 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 106.7/106.7 kB 16.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading py7zr-0.21.0-py3-none-any.whl (67 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 67.6/67.6 kB 10.7 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading dill-0.3.5.1-py2.py3-none-any.whl (95 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 95.8/95.8 kB 15.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading inflate64-1.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (93 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 93.1/93.1 kB 16.5 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading multivolumefile-0.2.3-py3-none-any.whl (17 kB)\u001b[0m\n",
      "\u001b[34mDownloading pybcj-1.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 49.7/49.7 kB 8.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading pycryptodomex-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 2.1/2.1 MB 88.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading pyppmd-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 138.9/138.9 kB 23.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading pyzstd-0.16.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (413 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 413.8/413.8 kB 45.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading responses-0.18.0-py3-none-any.whl (38 kB)\u001b[0m\n",
      "\u001b[34mDownloading tokenizers-0.12.1-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (6.6 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 6.6/6.6 MB 103.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading lxml-5.2.2-cp310-cp310-manylinux_2_28_x86_64.whl (5.0 MB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 5.0/5.0 MB 105.8 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading multiprocess-0.70.13-py310-none-any.whl (133 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 133.1/133.1 kB 19.9 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mDownloading portalocker-2.8.2-py3-none-any.whl (17 kB)\u001b[0m\n",
      "\u001b[34mDownloading texttable-1.7.0-py2.py3-none-any.whl (10 kB)\u001b[0m\n",
      "\u001b[34mDownloading xxhash-3.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\u001b[0m\n",
      "\u001b[34m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 194.1/194.1 kB 30.2 MB/s eta 0:00:00\u001b[0m\n",
      "\u001b[34mInstalling collected packages: tokenizers, texttable, sentencepiece, xxhash, pyzstd, pyppmd, pycryptodomex, pybcj, portalocker, nltk, multivolumefile, lxml, inflate64, dill, sacrebleu, responses, py7zr, multiprocess, transformers, datasets, evaluate\u001b[0m\n",
      "\u001b[34mAttempting uninstall: tokenizers\u001b[0m\n",
      "\u001b[34mFound existing installation: tokenizers 0.15.0\u001b[0m\n",
      "\u001b[34mUninstalling tokenizers-0.15.0:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled tokenizers-0.15.0\u001b[0m\n",
      "\u001b[34mAttempting uninstall: dill\u001b[0m\n",
      "\u001b[34mFound existing installation: dill 0.3.7\u001b[0m\n",
      "\u001b[34mUninstalling dill-0.3.7:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled dill-0.3.7\u001b[0m\n",
      "\u001b[34mAttempting uninstall: multiprocess\u001b[0m\n",
      "\u001b[34mFound existing installation: multiprocess 0.70.15\u001b[0m\n",
      "\u001b[34mUninstalling multiprocess-0.70.15:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled multiprocess-0.70.15\u001b[0m\n",
      "\u001b[34mAttempting uninstall: transformers\u001b[0m\n",
      "\u001b[34mFound existing installation: transformers 4.38.2\u001b[0m\n",
      "\u001b[34mUninstalling transformers-4.38.2:\u001b[0m\n",
      "\u001b[34mSuccessfully uninstalled transformers-4.38.2\u001b[0m\n",
      "\u001b[34mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\u001b[0m\n",
      "\u001b[34mpathos 0.3.1 requires dill>=0.3.7, but you have dill 0.3.5.1 which is incompatible.\u001b[0m\n",
      "\u001b[34mpathos 0.3.1 requires multiprocess>=0.70.15, but you have multiprocess 0.70.13 which is incompatible.\u001b[0m\n",
      "\u001b[34mSuccessfully installed datasets-2.3.2 dill-0.3.5.1 evaluate-0.4.2 inflate64-1.0.0 lxml-5.2.2 multiprocess-0.70.13 multivolumefile-0.2.3 nltk-3.8.1 portalocker-2.8.2 py7zr-0.21.0 pybcj-1.0.2 pycryptodomex-3.20.0 pyppmd-1.1.0 pyzstd-0.16.0 responses-0.18.0 sacrebleu-2.4.2 sentencepiece-0.2.0 texttable-1.7.0 tokenizers-0.12.1 transformers-4.22.1 xxhash-3.4.1\u001b[0m\n",
      "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
      "\u001b[34m[notice] A new release of pip is available: 23.3.1 -> 24.0\u001b[0m\n",
      "\u001b[34m[notice] To update, run: pip install --upgrade pip\u001b[0m\n",
      "\u001b[34mThe cache for model files in Transformers v4.22.0 has been updated. Migrating your old cache. This is a one-time only operation. You can interrupt this and resume the migration later on by calling `transformers.utils.move_cache()`.\u001b[0m\n",
      "\u001b[34mMoving 0 files to the new cache system\u001b[0m\n",
      "\u001b[34m0it [00:00, ?it/s]\u001b[0m\n",
      "\u001b[34m0it [00:00, ?it/s]\u001b[0m\n",
      "\u001b[34mThe following values were not passed to `accelerate launch` and had defaults used instead:\u001b[0m\n",
      "\u001b[34m#011`--num_processes` was set to a value of `8`\u001b[0m\n",
      "\u001b[34m#011#011More than one GPU was found, enabling multi-GPU training.\u001b[0m\n",
      "\u001b[34m#011#011If this was unintended please pass in `--num_processes=1`.\u001b[0m\n",
      "\u001b[34m#011`--num_machines` was set to a value of `1`\u001b[0m\n",
      "\u001b[34m#011`--mixed_precision` was set to a value of `'no'`\u001b[0m\n",
      "\u001b[34m#011`--dynamo_backend` was set to a value of `'no'`\u001b[0m\n",
      "\u001b[34mTo avoid this warning pass in values for each of the problematic parameters or run `accelerate config`.\u001b[0m\n",
      "\u001b[34m06/07/2024 04:25:45 - INFO - __main__ - Distributed environment: MULTI_GPU  Backend: nccl\u001b[0m\n",
      "\u001b[34mNum processes: 8\u001b[0m\n",
      "\u001b[34mProcess index: 4\u001b[0m\n",
      "\u001b[34mLocal process index: 4\u001b[0m\n",
      "\u001b[34mDevice: cuda:4\u001b[0m\n",
      "\u001b[34mMixed precision type: no\u001b[0m\n",
      "\u001b[34m06/07/2024 04:25:45 - INFO - __main__ - Distributed environment: MULTI_GPU  Backend: nccl\u001b[0m\n",
      "\u001b[34mNum processes: 8\u001b[0m\n",
      "\u001b[34mProcess index: 6\u001b[0m\n",
      "\u001b[34mLocal process index: 6\u001b[0m\n",
      "\u001b[34mDevice: cuda:6\u001b[0m\n",
      "\u001b[34mMixed precision type: no\u001b[0m\n",
      "\u001b[34m06/07/2024 04:25:45 - INFO - __main__ - Distributed environment: MULTI_GPU  Backend: nccl\u001b[0m\n",
      "\u001b[34mNum processes: 8\u001b[0m\n",
      "\u001b[34mProcess index: 1\u001b[0m\n",
      "\u001b[34mLocal process index: 1\u001b[0m\n",
      "\u001b[34mDevice: cuda:1\u001b[0m\n",
      "\u001b[34mMixed precision type: no\u001b[0m\n",
      "\u001b[34m06/07/2024 04:25:45 - INFO - __main__ - Distributed environment: MULTI_GPU  Backend: nccl\u001b[0m\n",
      "\u001b[34mNum processes: 8\u001b[0m\n",
      "\u001b[34mProcess index: 2\u001b[0m\n",
      "\u001b[34mLocal process index: 2\u001b[0m\n",
      "\u001b[34mDevice: cuda:2\u001b[0m\n",
      "\u001b[34mMixed precision type: no\u001b[0m\n",
      "\u001b[34m06/07/2024 04:25:45 - INFO - __main__ - Distributed environment: MULTI_GPU  Backend: nccl\u001b[0m\n",
      "\u001b[34mNum processes: 8\u001b[0m\n",
      "\u001b[34mProcess index: 7\u001b[0m\n",
      "\u001b[34mLocal process index: 7\u001b[0m\n",
      "\u001b[34mDevice: cuda:7\u001b[0m\n",
      "\u001b[34mMixed precision type: no\u001b[0m\n",
      "\u001b[34m06/07/2024 04:25:45 - INFO - __main__ - Distributed environment: MULTI_GPU  Backend: nccl\u001b[0m\n",
      "\u001b[34mNum processes: 8\u001b[0m\n",
      "\u001b[34mProcess index: 3\u001b[0m\n",
      "\u001b[34mLocal process index: 3\u001b[0m\n",
      "\u001b[34mDevice: cuda:3\u001b[0m\n",
      "\u001b[34mMixed precision type: no\u001b[0m\n",
      "\u001b[34m06/07/2024 04:25:45 - INFO - __main__ - Distributed environment: MULTI_GPU  Backend: nccl\u001b[0m\n",
      "\u001b[34mNum processes: 8\u001b[0m\n",
      "\u001b[34mProcess index: 0\u001b[0m\n",
      "\u001b[34mLocal process index: 0\u001b[0m\n",
      "\u001b[34mDevice: cuda:0\u001b[0m\n",
      "\u001b[34mMixed precision type: no\u001b[0m\n",
      "\u001b[34m06/07/2024 04:25:45 - INFO - __main__ - Distributed environment: MULTI_GPU  Backend: nccl\u001b[0m\n",
      "\u001b[34mNum processes: 8\u001b[0m\n",
      "\u001b[34mProcess index: 5\u001b[0m\n",
      "\u001b[34mLocal process index: 5\u001b[0m\n",
      "\u001b[34mDevice: cuda:5\u001b[0m\n",
      "\u001b[34mMixed precision type: no\u001b[0m\n",
      "\u001b[34mNCCL version 2.17.1+cuda11.8\u001b[0m\n",
      "\u001b[34malgo-1:79:192 [0] configure_nvls_option:287 NCCL WARN NET/OFI Could not find ncclGetVersion symbol\u001b[0m\n",
      "\u001b[34malgo-1:79:192 [0] nccl_net_ofi_init:1237 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\u001b[0m\n",
      "\u001b[34malgo-1:86:193 [7] configure_nvls_option:287 NCCL WARN NET/OFI Could not find ncclGetVersion symbol\u001b[0m\n",
      "\u001b[34malgo-1:85:195 [6] configure_nvls_option:287 NCCL WARN NET/OFI Could not find ncclGetVersion symbol\u001b[0m\n",
      "\u001b[34malgo-1:84:196 [5] configure_nvls_option:287 NCCL WARN NET/OFI Could not find ncclGetVersion symbol\u001b[0m\n",
      "\u001b[34malgo-1:80:197 [1] configure_nvls_option:287 NCCL WARN NET/OFI Could not find ncclGetVersion symbol\u001b[0m\n",
      "\u001b[34malgo-1:86:193 [7] nccl_net_ofi_init:1237 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\u001b[0m\n",
      "\u001b[34malgo-1:85:195 [6] nccl_net_ofi_init:1237 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\u001b[0m\n",
      "\u001b[34malgo-1:84:196 [5] nccl_net_ofi_init:1237 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\u001b[0m\n",
      "\u001b[34malgo-1:80:197 [1] nccl_net_ofi_init:1237 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\u001b[0m\n",
      "\u001b[34malgo-1:81:199 [2] configure_nvls_option:287 NCCL WARN NET/OFI Could not find ncclGetVersion symbol\u001b[0m\n",
      "\u001b[34malgo-1:82:198 [3] configure_nvls_option:287 NCCL WARN NET/OFI Could not find ncclGetVersion symbol\u001b[0m\n",
      "\u001b[34malgo-1:83:194 [4] configure_nvls_option:287 NCCL WARN NET/OFI Could not find ncclGetVersion symbol\u001b[0m\n",
      "\u001b[34malgo-1:81:199 [2] nccl_net_ofi_init:1237 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\u001b[0m\n",
      "\u001b[34malgo-1:82:198 [3] nccl_net_ofi_init:1237 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\u001b[0m\n",
      "\u001b[34malgo-1:83:194 [4] nccl_net_ofi_init:1237 NCCL WARN NET/OFI aws-ofi-nccl initialization failed\u001b[0m\n",
      "\u001b[34mDownloading and preparing dataset parquet/smangrul--MuDoConv to /root/.cache/huggingface/datasets/smangrul___parquet/smangrul--MuDoConv-d107ce67c68b7dac/0.0.0/7328ef7ee03eaf3f86ae40594d46a1cec86161704e02dd19f232d81eee72ade8...\u001b[0m\n",
      "\u001b[34m06/07/2024 04:25:51 - WARNING - datasets.builder - Using custom data configuration smangrul--MuDoConv-d107ce67c68b7dac\u001b[0m\n",
      "\u001b[34mDownloading data files:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mDownloading data:   0%|          | 0.00/5.57M [00:00<?, ?B/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data: 100%|██████████| 5.57M/5.57M [00:00<00:00, 86.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading data:   0%|          | 0.00/22.7M [00:00<?, ?B/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  38%|███▊      | 8.68M/22.7M [00:00<00:00, 86.8MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  80%|████████  | 18.3M/22.7M [00:00<00:00, 92.1MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data: 100%|██████████| 22.7M/22.7M [00:00<00:00, 92.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading data:   0%|          | 0.00/19.8M [00:00<?, ?B/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  36%|███▌      | 7.16M/19.8M [00:00<00:00, 71.6MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  78%|███████▊  | 15.5M/19.8M [00:00<00:00, 78.4MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data: 100%|██████████| 19.8M/19.8M [00:00<00:00, 79.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading data:   0%|          | 0.00/7.72M [00:00<?, ?B/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data: 100%|██████████| 7.72M/7.72M [00:00<00:00, 84.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading data:   0%|          | 0.00/5.98M [00:00<?, ?B/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data: 100%|██████████| 5.98M/5.98M [00:00<00:00, 84.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading data:   0%|          | 0.00/28.3M [00:00<?, ?B/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  29%|██▊       | 8.07M/28.3M [00:00<00:00, 80.7MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  61%|██████    | 17.2M/28.3M [00:00<00:00, 86.6MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  93%|█████████▎| 26.3M/28.3M [00:00<00:00, 88.9MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data: 100%|██████████| 28.3M/28.3M [00:00<00:00, 88.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading data:   0%|          | 0.00/9.68M [00:00<?, ?B/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  85%|████████▍ | 8.21M/9.68M [00:00<00:00, 82.1MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data: 100%|██████████| 9.68M/9.68M [00:00<00:00, 83.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading data:   0%|          | 0.00/6.01M [00:00<?, ?B/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data: 100%|██████████| 6.01M/6.01M [00:00<00:00, 77.5MB/s]\u001b[0m\n",
      "\u001b[34mDownloading data:   0%|          | 0.00/14.6M [00:00<?, ?B/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  56%|█████▌    | 8.17M/14.6M [00:00<00:00, 81.7MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data: 100%|██████████| 14.6M/14.6M [00:00<00:00, 86.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading data:   0%|          | 0.00/10.8M [00:00<?, ?B/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  81%|████████  | 8.70M/10.8M [00:00<00:00, 87.0MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data: 100%|██████████| 10.8M/10.8M [00:00<00:00, 89.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading data:   0%|          | 0.00/19.5M [00:00<?, ?B/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  37%|███▋      | 7.23M/19.5M [00:00<00:00, 72.3MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data:  79%|███████▉  | 15.4M/19.5M [00:00<00:00, 77.7MB/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data: 100%|██████████| 19.5M/19.5M [00:00<00:00, 79.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading data files:  33%|███▎      | 1/3 [00:02<00:05,  2.94s/it]\u001b[0m\n",
      "\u001b[34mDownloading data:   0%|          | 0.00/1.17M [00:00<?, ?B/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data: 100%|██████████| 1.17M/1.17M [00:00<00:00, 85.6MB/s]\u001b[0m\n",
      "\u001b[34mDownloading data:   0%|          | 0.00/700k [00:00<?, ?B/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data: 100%|██████████| 700k/700k [00:00<00:00, 79.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading data:   0%|          | 0.00/980k [00:00<?, ?B/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data: 100%|██████████| 980k/980k [00:00<00:00, 78.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading data:   0%|          | 0.00/1.73M [00:00<?, ?B/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data: 100%|██████████| 1.73M/1.73M [00:00<00:00, 87.0MB/s]\u001b[0m\n",
      "\u001b[34mDownloading data:   0%|          | 0.00/1.27M [00:00<?, ?B/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data: 100%|██████████| 1.27M/1.27M [00:00<00:00, 84.8MB/s]\u001b[0m\n",
      "\u001b[34mDownloading data:   0%|          | 0.00/1.04M [00:00<?, ?B/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data: 100%|██████████| 1.04M/1.04M [00:00<00:00, 80.3MB/s]\u001b[0m\n",
      "\u001b[34mDownloading data files:  67%|██████▋   | 2/3 [00:03<00:01,  1.64s/it]\u001b[0m\n",
      "\u001b[34mDownloading data:   0%|          | 0.00/1.19M [00:00<?, ?B/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data: 100%|██████████| 1.19M/1.19M [00:00<00:00, 84.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading data:   0%|          | 0.00/1.37M [00:00<?, ?B/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data: 100%|██████████| 1.37M/1.37M [00:00<00:00, 81.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading data:   0%|          | 0.00/720k [00:00<?, ?B/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data: 100%|██████████| 720k/720k [00:00<00:00, 74.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading data:   0%|          | 0.00/1.02M [00:00<?, ?B/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data: 100%|██████████| 1.02M/1.02M [00:00<00:00, 81.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading data:   0%|          | 0.00/1.28M [00:00<?, ?B/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data: 100%|██████████| 1.28M/1.28M [00:00<00:00, 84.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading data:   0%|          | 0.00/130k [00:00<?, ?B/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data: 100%|██████████| 130k/130k [00:00<00:00, 70.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading data:   0%|          | 0.00/1.06M [00:00<?, ?B/s]#033[A\u001b[0m\n",
      "\u001b[34mDownloading data: 100%|██████████| 1.06M/1.06M [00:00<00:00, 83.9MB/s]\u001b[0m\n",
      "\u001b[34mDownloading data files: 100%|██████████| 3/3 [00:04<00:00,  1.26s/it]\u001b[0m\n",
      "\u001b[34mDownloading data files: 100%|██████████| 3/3 [00:04<00:00,  1.49s/it]\u001b[0m\n",
      "\u001b[34mExtracting data files:   0%|          | 0/3 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mExtracting data files: 100%|██████████| 3/3 [00:00<00:00, 231.26it/s]\u001b[0m\n",
      "\u001b[34m0 tables [00:00, ? tables/s]\u001b[0m\n",
      "\u001b[34m14 tables [00:00, 138.02 tables/s]\u001b[0m\n",
      "\u001b[34m33 tables [00:00, 164.48 tables/s]\u001b[0m\n",
      "\u001b[34m59 tables [00:00, 205.80 tables/s]\u001b[0m\n",
      "\u001b[34m87 tables [00:00, 231.94 tables/s]\u001b[0m\n",
      "\u001b[34m123 tables [00:00, 276.69 tables/s]\u001b[0m\n",
      "\u001b[34m162 tables [00:00, 313.41 tables/s]\u001b[0m\n",
      "\u001b[34m194 tables [00:00, 296.20 tables/s]\u001b[0m\n",
      "\u001b[34m227 tables [00:00, 304.76 tables/s]\u001b[0m\n",
      "\u001b[34m263 tables [00:00, 309.40 tables/s]\u001b[0m\n",
      "\u001b[34m0 tables [00:00, ? tables/s]\u001b[0m\n",
      "\u001b[34m0 tables [00:00, ? tables/s]\u001b[0m\n",
      "\u001b[34mDataset parquet downloaded and prepared to /root/.cache/huggingface/datasets/smangrul___parquet/smangrul--MuDoConv-d107ce67c68b7dac/0.0.0/7328ef7ee03eaf3f86ae40594d46a1cec86161704e02dd19f232d81eee72ade8. Subsequent calls will reuse this data.\u001b[0m\n",
      "\u001b[34m0%|          | 0/3 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m100%|██████████| 3/3 [00:00<00:00, 338.47it/s]\u001b[0m\n",
      "\u001b[34m0%|          | 0/3 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m0%|          | 0/3 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m100%|██████████| 3/3 [00:00<00:00, 396.49it/s]\u001b[0m\n",
      "\u001b[34m0%|          | 0/3 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m100%|██████████| 3/3 [00:00<00:00, 407.83it/s]\u001b[0m\n",
      "\u001b[34m100%|██████████| 3/3 [00:00<00:00, 393.89it/s]\u001b[0m\n",
      "\u001b[34m0%|          | 0/3 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m0%|          | 0/3 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m100%|██████████| 3/3 [00:00<00:00, 426.87it/s]\u001b[0m\n",
      "\u001b[34m100%|██████████| 3/3 [00:00<00:00, 410.27it/s]\u001b[0m\n",
      "\u001b[34m06/07/2024 04:25:58 - WARNING - datasets.builder - Reusing dataset parquet (/root/.cache/huggingface/datasets/smangrul___parquet/smangrul--MuDoConv-d107ce67c68b7dac/0.0.0/7328ef7ee03eaf3f86ae40594d46a1cec86161704e02dd19f232d81eee72ade8)\u001b[0m\n",
      "\u001b[34m0%|          | 0/3 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m100%|██████████| 3/3 [00:00<00:00, 421.79it/s]\u001b[0m\n",
      "\u001b[34mconfig.json:   0%|          | 0.00/1.57k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mconfig.json: 100%|██████████| 1.57k/1.57k [00:00<00:00, 10.4MB/s]\u001b[0m\n",
      "\u001b[34m0%|          | 0/3 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34m100%|██████████| 3/3 [00:00<00:00, 393.84it/s]\u001b[0m\n",
      "\u001b[34mtokenizer_config.json:   0%|          | 0.00/1.15k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mtokenizer_config.json: 100%|██████████| 1.15k/1.15k [00:00<00:00, 6.45MB/s]\u001b[0m\n",
      "\u001b[34mloading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--blenderbot-400M-distill/snapshots/eaaf64e3be20ad1f1fb0bdf689565ba52c97eafe/config.json\u001b[0m\n",
      "\u001b[34mModel config BlenderbotConfig {\n",
      "  \"_name_or_path\": \"facebook/blenderbot-400M-distill\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": true,\n",
      "  \"architectures\": [\n",
      "    \"BlenderbotForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 1280,\n",
      "  \"decoder_attention_heads\": 32,\n",
      "  \"decoder_ffn_dim\": 5120,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 12,\n",
      "  \"decoder_start_token_id\": 1,\n",
      "  \"do_blenderbot_90_layernorm\": true,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 32,\n",
      "  \"encoder_ffn_dim\": 5120,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 2,\n",
      "  \"encoder_no_repeat_ngram_size\": 3,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"extra_layer_norm\": false,\n",
      "  \"extra_pos_embeddings\": 0,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layernorm_variant\": \"prelayernorm\",\n",
      "  \"length_penalty\": 0.65,\n",
      "  \"max_length\": 60,\n",
      "  \"max_position_embeddings\": 128,\n",
      "  \"min_length\": 20,\n",
      "  \"model_type\": \"blenderbot\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": true,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 10,\n",
      "  \"num_hidden_layers\": 2,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"scale_embedding\": true,\n",
      "  \"static_position_embeddings\": false,\n",
      "  \"transformers_version\": \"4.22.1\",\n",
      "  \"unk_token_id\": 3,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 8008\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mloading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--blenderbot-400M-distill/snapshots/eaaf64e3be20ad1f1fb0bdf689565ba52c97eafe/config.json\u001b[0m\n",
      "\u001b[34mModel config BlenderbotConfig {\n",
      "  \"_name_or_path\": \"facebook/blenderbot-400M-distill\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": true,\n",
      "  \"architectures\": [\n",
      "    \"BlenderbotForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 1280,\n",
      "  \"decoder_attention_heads\": 32,\n",
      "  \"decoder_ffn_dim\": 5120,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 12,\n",
      "  \"decoder_start_token_id\": 1,\n",
      "  \"do_blenderbot_90_layernorm\": true,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 32,\n",
      "  \"encoder_ffn_dim\": 5120,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 2,\n",
      "  \"encoder_no_repeat_ngram_size\": 3,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"extra_layer_norm\": false,\n",
      "  \"extra_pos_embeddings\": 0,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layernorm_variant\": \"prelayernorm\",\n",
      "  \"length_penalty\": 0.65,\n",
      "  \"max_length\": 60,\n",
      "  \"max_position_embeddings\": 128,\n",
      "  \"min_length\": 20,\n",
      "  \"model_type\": \"blenderbot\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": true,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 10,\n",
      "  \"num_hidden_layers\": 2,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"scale_embedding\": true,\n",
      "  \"static_position_embeddings\": false,\n",
      "  \"transformers_version\": \"4.22.1\",\n",
      "  \"unk_token_id\": 3,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 8008\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mvocab.json:   0%|          | 0.00/127k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mvocab.json: 100%|██████████| 127k/127k [00:00<00:00, 31.1MB/s]\u001b[0m\n",
      "\u001b[34mmerges.txt:   0%|          | 0.00/62.9k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mmerges.txt: 100%|██████████| 62.9k/62.9k [00:00<00:00, 251MB/s]\u001b[0m\n",
      "\u001b[34madded_tokens.json:   0%|          | 0.00/16.0 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34madded_tokens.json: 100%|██████████| 16.0/16.0 [00:00<00:00, 133kB/s]\u001b[0m\n",
      "\u001b[34mspecial_tokens_map.json:   0%|          | 0.00/772 [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mspecial_tokens_map.json: 100%|██████████| 772/772 [00:00<00:00, 5.17MB/s]\u001b[0m\n",
      "\u001b[34mloading file vocab.json from cache at /root/.cache/huggingface/hub/models--facebook--blenderbot-400M-distill/snapshots/eaaf64e3be20ad1f1fb0bdf689565ba52c97eafe/vocab.json\u001b[0m\n",
      "\u001b[34mloading file merges.txt from cache at /root/.cache/huggingface/hub/models--facebook--blenderbot-400M-distill/snapshots/eaaf64e3be20ad1f1fb0bdf689565ba52c97eafe/merges.txt\u001b[0m\n",
      "\u001b[34mloading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--facebook--blenderbot-400M-distill/snapshots/eaaf64e3be20ad1f1fb0bdf689565ba52c97eafe/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mloading file added_tokens.json from cache at /root/.cache/huggingface/hub/models--facebook--blenderbot-400M-distill/snapshots/eaaf64e3be20ad1f1fb0bdf689565ba52c97eafe/added_tokens.json\u001b[0m\n",
      "\u001b[34mloading file special_tokens_map.json from cache at /root/.cache/huggingface/hub/models--facebook--blenderbot-400M-distill/snapshots/eaaf64e3be20ad1f1fb0bdf689565ba52c97eafe/special_tokens_map.json\u001b[0m\n",
      "\u001b[34mloading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--blenderbot-400M-distill/snapshots/eaaf64e3be20ad1f1fb0bdf689565ba52c97eafe/config.json\u001b[0m\n",
      "\u001b[34mModel config BlenderbotConfig {\n",
      "  \"_name_or_path\": \"facebook/blenderbot-400M-distill\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": true,\n",
      "  \"architectures\": [\n",
      "    \"BlenderbotForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 1280,\n",
      "  \"decoder_attention_heads\": 32,\n",
      "  \"decoder_ffn_dim\": 5120,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 12,\n",
      "  \"decoder_start_token_id\": 1,\n",
      "  \"do_blenderbot_90_layernorm\": true,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 32,\n",
      "  \"encoder_ffn_dim\": 5120,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 2,\n",
      "  \"encoder_no_repeat_ngram_size\": 3,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"extra_layer_norm\": false,\n",
      "  \"extra_pos_embeddings\": 0,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layernorm_variant\": \"prelayernorm\",\n",
      "  \"length_penalty\": 0.65,\n",
      "  \"max_length\": 60,\n",
      "  \"max_position_embeddings\": 128,\n",
      "  \"min_length\": 20,\n",
      "  \"model_type\": \"blenderbot\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": true,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 10,\n",
      "  \"num_hidden_layers\": 2,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"scale_embedding\": true,\n",
      "  \"static_position_embeddings\": false,\n",
      "  \"transformers_version\": \"4.22.1\",\n",
      "  \"unk_token_id\": 3,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 8008\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mAdding <mask> to the vocabulary\u001b[0m\n",
      "\u001b[34mloading configuration file config.json from cache at /root/.cache/huggingface/hub/models--facebook--blenderbot-400M-distill/snapshots/eaaf64e3be20ad1f1fb0bdf689565ba52c97eafe/config.json\u001b[0m\n",
      "\u001b[34mModel config BlenderbotConfig {\n",
      "  \"_name_or_path\": \"facebook/blenderbot-400M-distill\",\n",
      "  \"activation_dropout\": 0.0,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": true,\n",
      "  \"architectures\": [\n",
      "    \"BlenderbotForConditionalGeneration\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"classif_dropout\": 0.0,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 1280,\n",
      "  \"decoder_attention_heads\": 32,\n",
      "  \"decoder_ffn_dim\": 5120,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 12,\n",
      "  \"decoder_start_token_id\": 1,\n",
      "  \"do_blenderbot_90_layernorm\": true,\n",
      "  \"dropout\": 0.1,\n",
      "  \"encoder_attention_heads\": 32,\n",
      "  \"encoder_ffn_dim\": 5120,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 2,\n",
      "  \"encoder_no_repeat_ngram_size\": 3,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"extra_layer_norm\": false,\n",
      "  \"extra_pos_embeddings\": 0,\n",
      "  \"force_bos_token_to_be_generated\": false,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layernorm_variant\": \"prelayernorm\",\n",
      "  \"length_penalty\": 0.65,\n",
      "  \"max_length\": 60,\n",
      "  \"max_position_embeddings\": 128,\n",
      "  \"min_length\": 20,\n",
      "  \"model_type\": \"blenderbot\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": true,\n",
      "  \"normalize_embedding\": false,\n",
      "  \"num_beams\": 10,\n",
      "  \"num_hidden_layers\": 2,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"scale_embedding\": true,\n",
      "  \"static_position_embeddings\": false,\n",
      "  \"transformers_version\": \"4.22.1\",\n",
      "  \"unk_token_id\": 3,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 8008\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mpytorch_model.bin:   0%|          | 0.00/730M [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mpytorch_model.bin:   6%|▌         | 41.9M/730M [00:00<00:01, 397MB/s]\u001b[0m\n",
      "\u001b[34mpytorch_model.bin:  13%|█▎        | 94.4M/730M [00:00<00:01, 424MB/s]\u001b[0m\n",
      "\u001b[34mpytorch_model.bin:  20%|██        | 147M/730M [00:00<00:01, 348MB/s]\u001b[0m\n",
      "\u001b[34mpytorch_model.bin:  26%|██▌       | 189M/730M [00:00<00:01, 352MB/s]\u001b[0m\n",
      "\u001b[34mpytorch_model.bin:  32%|███▏      | 231M/730M [00:00<00:01, 366MB/s]\u001b[0m\n",
      "\u001b[34mpytorch_model.bin:  37%|███▋      | 273M/730M [00:00<00:01, 381MB/s]\u001b[0m\n",
      "\u001b[34mpytorch_model.bin:  45%|████▍     | 325M/730M [00:00<00:01, 399MB/s]\u001b[0m\n",
      "\u001b[34mpytorch_model.bin:  50%|█████     | 367M/730M [00:00<00:01, 355MB/s]\u001b[0m\n",
      "\u001b[34mpytorch_model.bin:  56%|█████▌    | 409M/730M [00:01<00:00, 368MB/s]\u001b[0m\n",
      "\u001b[34mpytorch_model.bin:  63%|██████▎   | 461M/730M [00:01<00:00, 384MB/s]\u001b[0m\n",
      "\u001b[34mpytorch_model.bin:  70%|███████   | 514M/730M [00:01<00:00, 398MB/s]\u001b[0m\n",
      "\u001b[34mpytorch_model.bin:  76%|███████▌  | 556M/730M [00:01<00:00, 367MB/s]\u001b[0m\n",
      "\u001b[34mpytorch_model.bin:  82%|████████▏ | 598M/730M [00:01<00:00, 369MB/s]\u001b[0m\n",
      "\u001b[34mpytorch_model.bin:  88%|████████▊ | 640M/730M [00:01<00:00, 359MB/s]\u001b[0m\n",
      "\u001b[34mpytorch_model.bin:  93%|█████████▎| 682M/730M [00:01<00:00, 358MB/s]\u001b[0m\n",
      "\u001b[34mpytorch_model.bin: 100%|██████████| 730M/730M [00:01<00:00, 380MB/s]\u001b[0m\n",
      "\u001b[34mpytorch_model.bin: 100%|██████████| 730M/730M [00:01<00:00, 373MB/s]\u001b[0m\n",
      "\u001b[34mloading weights file pytorch_model.bin from cache at /root/.cache/huggingface/hub/models--facebook--blenderbot-400M-distill/snapshots/eaaf64e3be20ad1f1fb0bdf689565ba52c97eafe/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mAll model checkpoint weights were used when initializing BlenderbotForConditionalGeneration.\u001b[0m\n",
      "\u001b[34mAll the weights of BlenderbotForConditionalGeneration were initialized from the model checkpoint at facebook/blenderbot-400M-distill.\u001b[0m\n",
      "\u001b[34mIf your task is similar to the task the model of the checkpoint was trained on, you can already use BlenderbotForConditionalGeneration for predictions without further training.\u001b[0m\n",
      "\u001b[34m06/07/2024 04:26:04 - WARNING - datasets.fingerprint - Parameter 'function'=<function main.<locals>.preprocess_function at 0x7f0e542b31c0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   0%|          | 0/10 [00:00<?, ?ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  10%|█         | 1/10 [00:00<00:01,  5.26ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  20%|██        | 2/10 [00:00<00:01,  5.50ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  30%|███       | 3/10 [00:00<00:01,  5.58ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  40%|████      | 4/10 [00:00<00:01,  5.64ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  50%|█████     | 5/10 [00:00<00:00,  5.67ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  60%|██████    | 6/10 [00:01<00:00,  5.72ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  70%|███████   | 7/10 [00:01<00:00,  5.73ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  80%|████████  | 8/10 [00:01<00:00,  4.75ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  90%|█████████ | 9/10 [00:01<00:00,  5.04ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset: 100%|██████████| 10/10 [00:01<00:00,  5.26ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset: 100%|██████████| 10/10 [00:01<00:00,  5.35ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   0%|          | 0/112 [00:00<?, ?ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   1%|          | 1/112 [00:00<00:20,  5.52ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   2%|▏         | 2/112 [00:00<00:19,  5.62ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   3%|▎         | 3/112 [00:00<00:19,  5.64ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   4%|▎         | 4/112 [00:00<00:22,  4.83ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   4%|▍         | 5/112 [00:00<00:20,  5.13ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   5%|▌         | 6/112 [00:01<00:19,  5.34ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   6%|▋         | 7/112 [00:01<00:19,  5.47ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   7%|▋         | 8/112 [00:01<00:18,  5.54ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   8%|▊         | 9/112 [00:01<00:18,  5.62ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   9%|▉         | 10/112 [00:01<00:18,  5.66ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  10%|▉         | 11/112 [00:01<00:17,  5.71ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  11%|█         | 12/112 [00:02<00:24,  4.09ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  12%|█▏        | 13/112 [00:02<00:22,  4.48ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  12%|█▎        | 14/112 [00:02<00:20,  4.84ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  13%|█▎        | 15/112 [00:02<00:18,  5.13ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  14%|█▍        | 16/112 [00:03<00:17,  5.36ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  15%|█▌        | 17/112 [00:03<00:17,  5.51ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  16%|█▌        | 18/112 [00:03<00:16,  5.59ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  17%|█▋        | 19/112 [00:03<00:16,  5.66ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  18%|█▊        | 20/112 [00:03<00:16,  5.71ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  19%|█▉        | 21/112 [00:03<00:15,  5.76ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  20%|█▉        | 22/112 [00:04<00:15,  5.80ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  21%|██        | 23/112 [00:04<00:15,  5.82ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  21%|██▏       | 24/112 [00:04<00:15,  5.80ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  22%|██▏       | 25/112 [00:04<00:14,  5.82ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  23%|██▎       | 26/112 [00:04<00:14,  5.82ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  24%|██▍       | 27/112 [00:05<00:17,  4.84ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  25%|██▌       | 28/112 [00:05<00:16,  5.12ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  26%|██▌       | 29/112 [00:05<00:15,  5.29ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  27%|██▋       | 30/112 [00:05<00:15,  5.45ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  28%|██▊       | 31/112 [00:05<00:14,  5.58ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  29%|██▊       | 32/112 [00:05<00:14,  5.67ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  29%|██▉       | 33/112 [00:06<00:13,  5.74ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  30%|███       | 34/112 [00:06<00:13,  5.77ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  31%|███▏      | 35/112 [00:06<00:13,  5.82ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  32%|███▏      | 36/112 [00:06<00:12,  5.86ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  33%|███▎      | 37/112 [00:06<00:12,  5.86ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  34%|███▍      | 38/112 [00:07<00:14,  5.14ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  35%|███▍      | 39/112 [00:07<00:13,  5.39ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  36%|███▌      | 40/112 [00:07<00:13,  5.53ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  37%|███▋      | 41/112 [00:07<00:16,  4.31ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  38%|███▊      | 42/112 [00:07<00:14,  4.71ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  38%|███▊      | 43/112 [00:08<00:13,  5.02ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  39%|███▉      | 44/112 [00:08<00:13,  5.21ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  40%|████      | 45/112 [00:08<00:12,  5.39ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  41%|████      | 46/112 [00:08<00:11,  5.52ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  42%|████▏     | 47/112 [00:08<00:11,  5.63ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  43%|████▎     | 48/112 [00:08<00:11,  5.71ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  44%|████▍     | 49/112 [00:09<00:10,  5.78ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  45%|████▍     | 50/112 [00:09<00:10,  5.83ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  46%|████▌     | 51/112 [00:09<00:10,  5.87ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  46%|████▋     | 52/112 [00:09<00:10,  5.89ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  47%|████▋     | 53/112 [00:09<00:10,  5.90ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  48%|████▊     | 54/112 [00:09<00:09,  5.94ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  49%|████▉     | 55/112 [00:10<00:09,  5.98ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  50%|█████     | 56/112 [00:10<00:11,  4.94ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  51%|█████     | 57/112 [00:10<00:10,  5.22ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  52%|█████▏    | 58/112 [00:10<00:10,  5.39ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  53%|█████▎    | 59/112 [00:10<00:09,  5.53ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  54%|█████▎    | 60/112 [00:11<00:09,  5.56ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  54%|█████▍    | 61/112 [00:11<00:09,  5.66ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  55%|█████▌    | 62/112 [00:11<00:08,  5.75ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  56%|█████▋    | 63/112 [00:11<00:08,  5.83ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  57%|█████▋    | 64/112 [00:11<00:08,  5.88ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  58%|█████▊    | 65/112 [00:11<00:07,  5.89ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  59%|█████▉    | 66/112 [00:12<00:07,  5.94ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  60%|█████▉    | 67/112 [00:12<00:07,  5.96ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  61%|██████    | 68/112 [00:12<00:07,  5.53ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  62%|██████▏   | 69/112 [00:12<00:07,  5.64ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  62%|██████▎   | 70/112 [00:12<00:08,  4.83ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  63%|██████▎   | 71/112 [00:13<00:08,  5.12ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  64%|██████▍   | 72/112 [00:13<00:07,  5.36ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  65%|██████▌   | 73/112 [00:13<00:07,  5.51ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  66%|██████▌   | 74/112 [00:13<00:06,  5.63ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  67%|██████▋   | 75/112 [00:13<00:06,  5.71ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  68%|██████▊   | 76/112 [00:13<00:06,  5.79ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  69%|██████▉   | 77/112 [00:14<00:05,  5.86ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  70%|██████▉   | 78/112 [00:14<00:05,  5.88ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  71%|███████   | 79/112 [00:14<00:05,  5.92ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  71%|███████▏  | 80/112 [00:14<00:05,  5.96ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  72%|███████▏  | 81/112 [00:14<00:05,  5.97ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  73%|███████▎  | 82/112 [00:14<00:05,  5.94ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  74%|███████▍  | 83/112 [00:15<00:04,  5.97ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  75%|███████▌  | 84/112 [00:15<00:04,  5.94ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  76%|███████▌  | 85/112 [00:15<00:05,  4.52ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  77%|███████▋  | 86/112 [00:15<00:05,  4.84ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  78%|███████▊  | 87/112 [00:15<00:04,  5.09ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  79%|███████▊  | 88/112 [00:16<00:04,  5.27ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  79%|███████▉  | 89/112 [00:16<00:04,  5.42ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  80%|████████  | 90/112 [00:16<00:03,  5.55ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  81%|████████▏ | 91/112 [00:16<00:03,  5.62ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  82%|████████▏ | 92/112 [00:16<00:03,  5.68ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  83%|████████▎ | 93/112 [00:16<00:03,  5.74ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  84%|████████▍ | 94/112 [00:17<00:03,  5.78ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  85%|████████▍ | 95/112 [00:17<00:02,  5.80ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  86%|████████▌ | 96/112 [00:17<00:02,  5.77ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  87%|████████▋ | 97/112 [00:17<00:02,  5.76ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  88%|████████▊ | 98/112 [00:17<00:02,  5.77ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  88%|████████▊ | 99/112 [00:18<00:02,  4.81ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  89%|████████▉ | 100/112 [00:18<00:02,  5.09ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  90%|█████████ | 101/112 [00:18<00:02,  4.64ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  91%|█████████ | 102/112 [00:18<00:02,  4.95ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  92%|█████████▏| 103/112 [00:18<00:01,  5.12ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  93%|█████████▎| 104/112 [00:19<00:01,  5.30ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  94%|█████████▍| 105/112 [00:19<00:01,  5.43ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  95%|█████████▍| 106/112 [00:19<00:01,  5.53ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  96%|█████████▌| 107/112 [00:19<00:00,  5.58ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  96%|█████████▋| 108/112 [00:19<00:00,  5.64ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  97%|█████████▋| 109/112 [00:19<00:00,  5.66ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  98%|█████████▊| 110/112 [00:20<00:00,  5.70ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  99%|█████████▉| 111/112 [00:20<00:00,  5.72ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset: 100%|██████████| 112/112 [00:20<00:00,  6.13ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset: 100%|██████████| 112/112 [00:20<00:00,  5.49ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   0%|          | 0/1 [00:00<?, ?ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset: 100%|██████████| 1/1 [00:00<00:00,  5.53ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset: 100%|██████████| 1/1 [00:00<00:00,  5.53ba/s]\u001b[0m\n",
      "\u001b[34m06/07/2024 04:26:27 - INFO - __main__ - Sample 3506 of the training set: {'labels': [1858, 1751, 358, 319, 8, 7832, 19, 281, 504, 3180, 271, 1602, 358, 395, 2382, 19, 3022, 3597, 8, 2, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100], 'input_ids': [3879, 73, 311, 33, 281, 1490, 342, 19, 373, 1161, 281, 701, 945, 312, 265, 703, 8, 228, 2, 228, 1, 2183, 383, 513, 544, 319, 1568, 8, 466, 422, 304, 1861, 38, 228, 2, 228, 1, 1974, 328, 6180, 3835, 684, 1068, 19, 1151, 758, 281, 407, 371, 847, 480, 277, 343, 1243, 371, 281, 396, 21, 484, 5935, 341, 584, 618, 8, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}.\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:516: FutureWarning: The `use_fp16` property is deprecated and will be removed in version 1.0 of Accelerate use `Accelerator.mixed_precision == 'fp16'` instead.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   0%|          | 0/10 [00:00<?, ?ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   0%|          | 0/10 [00:00<?, ?ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   0%|          | 0/10 [00:00<?, ?ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   0%|          | 0/10 [00:00<?, ?ba/s]#015Running tokenizer on dataset:   0%|          | 0/10 [00:00<?, ?ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   0%|          | 0/10 [00:00<?, ?ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   0%|          | 0/10 [00:00<?, ?ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  10%|█         | 1/10 [00:00<00:02,  3.99ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  10%|█         | 1/10 [00:00<00:02,  3.48ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  10%|█         | 1/10 [00:00<00:02,  3.41ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  10%|█         | 1/10 [00:00<00:02,  3.28ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  10%|█         | 1/10 [00:00<00:02,  3.19ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  10%|█         | 1/10 [00:00<00:02,  3.11ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  10%|█         | 1/10 [00:00<00:02,  3.04ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  20%|██        | 2/10 [00:00<00:02,  3.97ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  20%|██        | 2/10 [00:00<00:02,  3.54ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  20%|██        | 2/10 [00:00<00:02,  3.45ba/s]#015Running tokenizer on dataset:  20%|██        | 2/10 [00:00<00:02,  3.48ba/s]#015Running tokenizer on dataset:  20%|██        | 2/10 [00:00<00:02,  3.46ba/s]#015Running tokenizer on dataset:  20%|██        | 2/10 [00:00<00:02,  3.38ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  20%|██        | 2/10 [00:00<00:02,  3.45ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  30%|███       | 3/10 [00:00<00:01,  3.92ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  30%|███       | 3/10 [00:00<00:01,  3.60ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  30%|███       | 3/10 [00:00<00:01,  3.60ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  30%|███       | 3/10 [00:00<00:01,  3.53ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  30%|███       | 3/10 [00:00<00:01,  3.51ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  30%|███       | 3/10 [00:00<00:02,  3.50ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  30%|███       | 3/10 [00:00<00:01,  3.56ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  40%|████      | 4/10 [00:00<00:01,  4.03ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  40%|████      | 4/10 [00:01<00:01,  3.60ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  40%|████      | 4/10 [00:01<00:01,  3.63ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  40%|████      | 4/10 [00:01<00:01,  3.57ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  40%|████      | 4/10 [00:01<00:01,  3.59ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  40%|████      | 4/10 [00:01<00:01,  3.55ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  40%|████      | 4/10 [00:01<00:01,  3.23ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  50%|█████     | 5/10 [00:01<00:01,  3.89ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  50%|█████     | 5/10 [00:01<00:01,  3.69ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  50%|█████     | 5/10 [00:01<00:01,  3.67ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  50%|█████     | 5/10 [00:01<00:01,  3.66ba/s]#015Running tokenizer on dataset:  50%|█████     | 5/10 [00:01<00:01,  3.63ba/s]#015Running tokenizer on dataset:  50%|█████     | 5/10 [00:01<00:01,  3.59ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  50%|█████     | 5/10 [00:01<00:01,  3.61ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  60%|██████    | 6/10 [00:01<00:00,  4.07ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  60%|██████    | 6/10 [00:01<00:01,  3.70ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  60%|██████    | 6/10 [00:01<00:01,  3.69ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  60%|██████    | 6/10 [00:01<00:01,  3.68ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  60%|██████    | 6/10 [00:01<00:01,  3.63ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  60%|██████    | 6/10 [00:01<00:01,  3.72ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  60%|██████    | 6/10 [00:01<00:01,  3.59ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  70%|███████   | 7/10 [00:01<00:00,  4.26ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  70%|███████   | 7/10 [00:01<00:00,  3.65ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  70%|███████   | 7/10 [00:01<00:00,  3.65ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  70%|███████   | 7/10 [00:01<00:00,  3.64ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  70%|███████   | 7/10 [00:01<00:00,  3.71ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  70%|███████   | 7/10 [00:01<00:00,  3.61ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  70%|███████   | 7/10 [00:01<00:00,  3.58ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  80%|████████  | 8/10 [00:02<00:00,  3.25ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  80%|████████  | 8/10 [00:02<00:00,  3.17ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  90%|█████████ | 9/10 [00:02<00:00,  3.73ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  80%|████████  | 8/10 [00:02<00:00,  3.21ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  80%|████████  | 8/10 [00:02<00:00,  3.09ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  80%|████████  | 8/10 [00:02<00:00,  3.02ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  80%|████████  | 8/10 [00:02<00:00,  2.89ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  80%|████████  | 8/10 [00:02<00:00,  2.84ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  90%|█████████ | 9/10 [00:02<00:00,  3.30ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  90%|█████████ | 9/10 [00:02<00:00,  3.26ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  90%|█████████ | 9/10 [00:02<00:00,  3.28ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset: 100%|██████████| 10/10 [00:02<00:00,  3.63ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset: 100%|██████████| 10/10 [00:02<00:00,  3.78ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  90%|█████████ | 9/10 [00:02<00:00,  3.22ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  90%|█████████ | 9/10 [00:02<00:00,  3.21ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:  90%|█████████ | 9/10 [00:02<00:00,  3.22ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   0%|          | 0/1 [00:00<?, ?ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset: 100%|██████████| 10/10 [00:02<00:00,  3.40ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset: 100%|██████████| 10/10 [00:02<00:00,  3.45ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset: 100%|██████████| 10/10 [00:02<00:00,  3.40ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset: 100%|██████████| 10/10 [00:02<00:00,  3.44ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset: 100%|██████████| 10/10 [00:02<00:00,  3.42ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset: 100%|██████████| 10/10 [00:02<00:00,  3.43ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset: 100%|██████████| 10/10 [00:02<00:00,  3.39ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset: 100%|██████████| 10/10 [00:02<00:00,  3.43ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset: 100%|██████████| 10/10 [00:02<00:00,  3.43ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset: 100%|██████████| 10/10 [00:02<00:00,  3.41ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset: 100%|██████████| 10/10 [00:02<00:00,  3.46ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset: 100%|██████████| 10/10 [00:02<00:00,  3.41ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   0%|          | 0/1 [00:00<?, ?ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset: 100%|██████████| 1/1 [00:00<00:00,  4.61ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset: 100%|██████████| 1/1 [00:00<00:00,  4.61ba/s]\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:516: FutureWarning: The `use_fp16` property is deprecated and will be removed in version 1.0 of Accelerate use `Accelerator.mixed_precision == 'fp16'` instead.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   0%|          | 0/1 [00:00<?, ?ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   0%|          | 0/1 [00:00<?, ?ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   0%|          | 0/1 [00:00<?, ?ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   0%|          | 0/1 [00:00<?, ?ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset:   0%|          | 0/1 [00:00<?, ?ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset: 100%|██████████| 1/1 [00:00<00:00,  3.92ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset: 100%|██████████| 1/1 [00:00<00:00,  3.92ba/s]\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:516: FutureWarning: The `use_fp16` property is deprecated and will be removed in version 1.0 of Accelerate use `Accelerator.mixed_precision == 'fp16'` instead.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset: 100%|██████████| 1/1 [00:00<00:00,  4.17ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset: 100%|██████████| 1/1 [00:00<00:00,  4.17ba/s]\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:516: FutureWarning: The `use_fp16` property is deprecated and will be removed in version 1.0 of Accelerate use `Accelerator.mixed_precision == 'fp16'` instead.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset: 100%|██████████| 1/1 [00:00<00:00,  3.95ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset: 100%|██████████| 1/1 [00:00<00:00,  3.95ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset: 100%|██████████| 1/1 [00:00<00:00,  4.05ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset: 100%|██████████| 1/1 [00:00<00:00,  4.04ba/s]\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:516: FutureWarning: The `use_fp16` property is deprecated and will be removed in version 1.0 of Accelerate use `Accelerator.mixed_precision == 'fp16'` instead.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:516: FutureWarning: The `use_fp16` property is deprecated and will be removed in version 1.0 of Accelerate use `Accelerator.mixed_precision == 'fp16'` instead.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset: 100%|██████████| 1/1 [00:00<00:00,  4.32ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset: 100%|██████████| 1/1 [00:00<00:00,  4.31ba/s]\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:516: FutureWarning: The `use_fp16` property is deprecated and will be removed in version 1.0 of Accelerate use `Accelerator.mixed_precision == 'fp16'` instead.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset: 100%|██████████| 1/1 [00:00<00:00,  4.36ba/s]\u001b[0m\n",
      "\u001b[34mRunning tokenizer on dataset: 100%|██████████| 1/1 [00:00<00:00,  4.36ba/s]\u001b[0m\n",
      "\u001b[34m/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:516: FutureWarning: The `use_fp16` property is deprecated and will be removed in version 1.0 of Accelerate use `Accelerator.mixed_precision == 'fp16'` instead.\n",
      "  warnings.warn(\u001b[0m\n",
      "\u001b[34mDownloading builder script:   0%|          | 0.00/2.85k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading builder script: 7.65kB [00:00, 21.1MB/s]\u001b[0m\n",
      "\u001b[34mDownloading builder script:   0%|          | 0.00/2.85k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading builder script: 7.65kB [00:00, 22.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading builder script:   0%|          | 0.00/2.85k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading builder script: 7.65kB [00:00, 19.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading builder script:   0%|          | 0.00/2.85k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading builder script: 7.65kB [00:00, 17.4MB/s]\u001b[0m\n",
      "\u001b[34mDownloading builder script:   0%|          | 0.00/2.85k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading builder script: 7.65kB [00:00, 18.7MB/s]\u001b[0m\n",
      "\u001b[34mDownloading builder script:   0%|          | 0.00/2.85k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading builder script: 7.65kB [00:00, 22.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading builder script:   0%|          | 0.00/2.85k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading builder script: 7.65kB [00:00, 21.2MB/s]\u001b[0m\n",
      "\u001b[34mDownloading builder script:   0%|          | 0.00/2.85k [00:00<?, ?B/s]\u001b[0m\n",
      "\u001b[34mDownloading builder script: 7.65kB [00:00, 20.8MB/s]\u001b[0m\n",
      "\u001b[34m06/07/2024 04:26:31 - INFO - __main__ - ***** Running training *****\u001b[0m\n",
      "\u001b[34m06/07/2024 04:26:31 - INFO - __main__ -   Num examples = 10000\u001b[0m\n",
      "\u001b[34m06/07/2024 04:26:31 - INFO - __main__ -   Num Epochs = 1\u001b[0m\n",
      "\u001b[34m06/07/2024 04:26:31 - INFO - __main__ -   Instantaneous batch size per device = 16\u001b[0m\n",
      "\u001b[34m06/07/2024 04:26:31 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 128\u001b[0m\n",
      "\u001b[34m06/07/2024 04:26:31 - INFO - __main__ -   Gradient Accumulation steps = 1\u001b[0m\n",
      "\u001b[34m06/07/2024 04:26:31 - INFO - __main__ -   Total optimization steps = 79\u001b[0m\n",
      "\u001b[34m0%|          | 0/79 [00:00<?, ?it/s]\u001b[0m\n",
      "\u001b[34mYou're using a BlenderbotTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\u001b[0m\n",
      "\u001b[34m1%|▏         | 1/79 [00:00<01:12,  1.07it/s]\u001b[0m\n",
      "\u001b[34m06/07/2024 04:26:32 - INFO - torch.nn.parallel.distributed - Reducer buckets have been rebuilt in this iteration.\u001b[0m\n",
      "\u001b[34m06/07/2024 04:26:32 - INFO - torch.nn.parallel.distributed - Reducer buckets have been rebuilt in this iteration.\u001b[0m\n",
      "\u001b[34m06/07/2024 04:26:32 - INFO - torch.nn.parallel.distributed - Reducer buckets have been rebuilt in this iteration.\u001b[0m\n",
      "\u001b[34m06/07/2024 04:26:32 - INFO - torch.nn.parallel.distributed - Reducer buckets have been rebuilt in this iteration.\u001b[0m\n",
      "\u001b[34m06/07/2024 04:26:32 - INFO - torch.nn.parallel.distributed - Reducer buckets have been rebuilt in this iteration.\u001b[0m\n",
      "\u001b[34m06/07/2024 04:26:32 - INFO - torch.nn.parallel.distributed - Reducer buckets have been rebuilt in this iteration.\u001b[0m\n",
      "\u001b[34m06/07/2024 04:26:32 - INFO - torch.nn.parallel.distributed - Reducer buckets have been rebuilt in this iteration.\u001b[0m\n",
      "\u001b[34m06/07/2024 04:26:32 - INFO - torch.nn.parallel.distributed - Reducer buckets have been rebuilt in this iteration.\u001b[0m\n",
      "\u001b[34m3%|▎         | 2/79 [00:01<00:40,  1.88it/s]\u001b[0m\n",
      "\u001b[34m4%|▍         | 3/79 [00:01<00:32,  2.32it/s]\u001b[0m\n",
      "\u001b[34m5%|▌         | 4/79 [00:01<00:28,  2.60it/s]\u001b[0m\n",
      "\u001b[34m6%|▋         | 5/79 [00:02<00:26,  2.78it/s]\u001b[0m\n",
      "\u001b[34m8%|▊         | 6/79 [00:02<00:25,  2.91it/s]\u001b[0m\n",
      "\u001b[34m9%|▉         | 7/79 [00:02<00:24,  3.00it/s]\u001b[0m\n",
      "\u001b[34m10%|█         | 8/79 [00:03<00:23,  3.06it/s]\u001b[0m\n",
      "\u001b[34m11%|█▏        | 9/79 [00:03<00:22,  3.10it/s]\u001b[0m\n",
      "\u001b[34m13%|█▎        | 10/79 [00:03<00:22,  3.12it/s]\u001b[0m\n",
      "\u001b[34m14%|█▍        | 11/79 [00:04<00:21,  3.15it/s]\u001b[0m\n",
      "\u001b[34m15%|█▌        | 12/79 [00:04<00:21,  3.16it/s]\u001b[0m\n",
      "\u001b[34m16%|█▋        | 13/79 [00:04<00:20,  3.17it/s]\u001b[0m\n",
      "\u001b[34m18%|█▊        | 14/79 [00:04<00:20,  3.18it/s]\u001b[0m\n",
      "\u001b[34m19%|█▉        | 15/79 [00:05<00:20,  3.18it/s]\u001b[0m\n",
      "\u001b[34m20%|██        | 16/79 [00:05<00:19,  3.19it/s]\u001b[0m\n",
      "\u001b[34m22%|██▏       | 17/79 [00:05<00:19,  3.19it/s]\u001b[0m\n",
      "\u001b[34m23%|██▎       | 18/79 [00:06<00:19,  3.19it/s]\u001b[0m\n",
      "\u001b[34m24%|██▍       | 19/79 [00:06<00:18,  3.19it/s]\u001b[0m\n",
      "\u001b[34m25%|██▌       | 20/79 [00:06<00:18,  3.19it/s]\u001b[0m\n",
      "\u001b[34m27%|██▋       | 21/79 [00:07<00:18,  3.19it/s]\u001b[0m\n",
      "\u001b[34m28%|██▊       | 22/79 [00:07<00:17,  3.19it/s]\u001b[0m\n",
      "\u001b[34m29%|██▉       | 23/79 [00:07<00:17,  3.19it/s]\u001b[0m\n",
      "\u001b[34m30%|███       | 24/79 [00:08<00:17,  3.19it/s]\u001b[0m\n",
      "\u001b[34m32%|███▏      | 25/79 [00:08<00:16,  3.19it/s]\u001b[0m\n",
      "\u001b[34m33%|███▎      | 26/79 [00:08<00:16,  3.19it/s]\u001b[0m\n",
      "\u001b[34m34%|███▍      | 27/79 [00:09<00:16,  3.19it/s]\u001b[0m\n",
      "\u001b[34m35%|███▌      | 28/79 [00:09<00:15,  3.19it/s]\u001b[0m\n",
      "\u001b[34m37%|███▋      | 29/79 [00:09<00:15,  3.19it/s]\u001b[0m\n",
      "\u001b[34m38%|███▊      | 30/79 [00:09<00:15,  3.19it/s]\u001b[0m\n",
      "\u001b[34m39%|███▉      | 31/79 [00:10<00:15,  3.19it/s]\u001b[0m\n",
      "\u001b[34m41%|████      | 32/79 [00:10<00:14,  3.19it/s]\u001b[0m\n",
      "\u001b[34m42%|████▏     | 33/79 [00:10<00:14,  3.19it/s]\u001b[0m\n",
      "\u001b[34m43%|████▎     | 34/79 [00:11<00:14,  3.19it/s]\u001b[0m\n",
      "\u001b[34m44%|████▍     | 35/79 [00:11<00:13,  3.19it/s]\u001b[0m\n",
      "\u001b[34m46%|████▌     | 36/79 [00:11<00:13,  3.19it/s]\u001b[0m\n",
      "\u001b[34m47%|████▋     | 37/79 [00:12<00:13,  3.19it/s]\u001b[0m\n",
      "\u001b[34m48%|████▊     | 38/79 [00:12<00:12,  3.19it/s]\u001b[0m\n",
      "\u001b[34m49%|████▉     | 39/79 [00:12<00:12,  3.19it/s]\u001b[0m\n",
      "\u001b[34m51%|█████     | 40/79 [00:13<00:12,  3.19it/s]\u001b[0m\n",
      "\u001b[34m52%|█████▏    | 41/79 [00:13<00:11,  3.19it/s]\u001b[0m\n",
      "\u001b[34m53%|█████▎    | 42/79 [00:13<00:11,  3.19it/s]\u001b[0m\n",
      "\u001b[34m54%|█████▍    | 43/79 [00:14<00:11,  3.19it/s]\u001b[0m\n",
      "\u001b[34m56%|█████▌    | 44/79 [00:14<00:10,  3.19it/s]\u001b[0m\n",
      "\u001b[34m57%|█████▋    | 45/79 [00:14<00:10,  3.19it/s]\u001b[0m\n",
      "\u001b[34m58%|█████▊    | 46/79 [00:14<00:10,  3.19it/s]\u001b[0m\n",
      "\u001b[34m59%|█████▉    | 47/79 [00:15<00:10,  3.19it/s]\u001b[0m\n",
      "\u001b[34m61%|██████    | 48/79 [00:15<00:09,  3.19it/s]\u001b[0m\n",
      "\u001b[34m62%|██████▏   | 49/79 [00:15<00:09,  3.19it/s]\u001b[0m\n",
      "\u001b[34m63%|██████▎   | 50/79 [00:16<00:09,  3.19it/s]\u001b[0m\n",
      "\u001b[34m65%|██████▍   | 51/79 [00:16<00:08,  3.19it/s]\u001b[0m\n",
      "\u001b[34m66%|██████▌   | 52/79 [00:16<00:08,  3.19it/s]\u001b[0m\n",
      "\u001b[34m67%|██████▋   | 53/79 [00:17<00:08,  3.19it/s]\u001b[0m\n",
      "\u001b[34m68%|██████▊   | 54/79 [00:17<00:07,  3.19it/s]\u001b[0m\n",
      "\u001b[34m70%|██████▉   | 55/79 [00:17<00:07,  3.19it/s]\u001b[0m\n",
      "\u001b[34m71%|███████   | 56/79 [00:18<00:07,  3.19it/s]\u001b[0m\n",
      "\u001b[34m72%|███████▏  | 57/79 [00:18<00:06,  3.19it/s]\u001b[0m\n",
      "\u001b[34m73%|███████▎  | 58/79 [00:18<00:06,  3.19it/s]\u001b[0m\n",
      "\u001b[34m75%|███████▍  | 59/79 [00:19<00:06,  3.18it/s]\u001b[0m\n",
      "\u001b[34m76%|███████▌  | 60/79 [00:19<00:05,  3.18it/s]\u001b[0m\n",
      "\u001b[34m77%|███████▋  | 61/79 [00:19<00:05,  3.18it/s]\u001b[0m\n",
      "\u001b[34m78%|███████▊  | 62/79 [00:19<00:05,  3.18it/s]\u001b[0m\n",
      "\u001b[34m80%|███████▉  | 63/79 [00:20<00:05,  3.19it/s]\u001b[0m\n",
      "\u001b[34m81%|████████  | 64/79 [00:20<00:04,  3.19it/s]\u001b[0m\n",
      "\u001b[34m82%|████████▏ | 65/79 [00:20<00:04,  3.19it/s]\u001b[0m\n",
      "\u001b[34m84%|████████▎ | 66/79 [00:21<00:04,  3.19it/s]\u001b[0m\n",
      "\u001b[34m85%|████████▍ | 67/79 [00:21<00:03,  3.19it/s]\u001b[0m\n",
      "\u001b[34m86%|████████▌ | 68/79 [00:21<00:03,  3.19it/s]\u001b[0m\n",
      "\u001b[34m87%|████████▋ | 69/79 [00:22<00:03,  3.19it/s]\u001b[0m\n",
      "\u001b[34m89%|████████▊ | 70/79 [00:22<00:02,  3.19it/s]\u001b[0m\n",
      "\u001b[34m90%|████████▉ | 71/79 [00:22<00:02,  3.19it/s]\u001b[0m\n",
      "\u001b[34m91%|█████████ | 72/79 [00:23<00:02,  3.18it/s]\u001b[0m\n",
      "\u001b[34m92%|█████████▏| 73/79 [00:23<00:01,  3.19it/s]\u001b[0m\n",
      "\u001b[34m94%|█████████▎| 74/79 [00:23<00:01,  3.19it/s]\u001b[0m\n",
      "\u001b[34m95%|█████████▍| 75/79 [00:24<00:01,  3.19it/s]\u001b[0m\n",
      "\u001b[34m96%|█████████▌| 76/79 [00:24<00:00,  3.19it/s]\u001b[0m\n",
      "\u001b[34m97%|█████████▋| 77/79 [00:24<00:00,  3.19it/s]\u001b[0m\n",
      "\u001b[34m99%|█████████▊| 78/79 [00:25<00:00,  3.19it/s]\u001b[0m\n",
      "\u001b[34m100%|██████████| 79/79 [00:25<00:00,  3.20it/s]\u001b[0m\n",
      "\u001b[34m06/07/2024 04:26:57 - INFO - __main__ - Epoch 0 training took 25.3166446685791 seconds\u001b[0m\n",
      "\u001b[34mstarting evaluation\u001b[0m\n",
      "\u001b[34m06/07/2024 04:27:01 - INFO - __main__ - printing few sample generations and corresponding labels from eval set\u001b[0m\n",
      "\u001b[34m06/07/2024 04:27:01 - INFO - __main__ - prompt | generated | label\u001b[0m\n",
      "\u001b[34m06/07/2024 04:27:01 - INFO - __main__ - chatbot: your persona: i work as an electrician. i always sleep 8 hours a day. </s>  <s> Which level are you at?</s> |  I'm at the level where I can get 8 hours of sleep at a time. How about you? |  I received on-the-job training when i first started\u001b[0m\n",
      "\u001b[34m06/07/2024 04:27:01 - INFO - __main__ - chatbot: your persona: i work as an electrician. i always sleep 8 hours a day. </s>  <s> Which level are you at? </s> <s> I received on-the-job training when i first started </s> <s> Thats great! How long have you been doing this work? </s> |  I've been working as an Electrician for about 10 years now.  What do you do? |  For a good number of years now.\u001b[0m\n",
      "\u001b[34m06/07/2024 04:27:01 - INFO - __main__ - chatbot: your persona: i work as an electrician. i always sleep 8 hours a day. </s>  <s> Thats great! How long have you been doing this work? </s> |  I've been working as an Electrician for about 5 years now. I love it! |  For a good number of years now.\u001b[0m\n",
      "\u001b[34m06/07/2024 04:27:01 - INFO - __main__ - chatbot: your persona: i work as an electrician. i always sleep 8 hours a day. </s>  <s> Thats great! How long have you been doing this work?  </s> <s> For a good number of years now. </s> <s> Sounds like it could be a dangerous job at times.</s> |  It can be at times, but I enjoy it. What do you do for a living? |  That it is,especially if you dont take the proper measures\u001b[0m\n",
      "\u001b[34m06/07/2024 04:27:01 - INFO - __main__ - chatbot: your persona: i work as an electrician. i always sleep 8 hours a day. </s>  <s> Sounds like it could be a dangerous job at times.</s> |  It can be, but I love what I do. What do you do for a living? |  That it is,especially if you dont take the proper measures\u001b[0m\n",
      "\u001b[34m06/07/2024 04:27:01 - INFO - __main__ - chatbot: your persona: i work as an electrician. i always sleep 8 hours a day. </s>  <s> Well you have entered a trade that will always guarantee you some work.</s> |  I hope so. I've been trying to find a new job since I quit my last one. |  Thats true,especially in this economy\u001b[0m\n",
      "\u001b[34m06/07/2024 04:27:01 - INFO - __main__ - chatbot: your persona: i work as an electrician. i always sleep 8 hours a day. </s>  <s> I have a pretty stable job myself, but mostly desk work</s> |  What do you do for a living? I work in an electrical warehouse. |  Do you enjoy it?\u001b[0m\n",
      "\u001b[34m06/07/2024 04:27:01 - INFO - __main__ - chatbot: your persona: i work as an electrician. i always sleep 8 hours a day. </s>  <s> I have a pretty stable job myself, but mostly desk work </s> <s> Do you enjoy it? </s> <s> I really do but sometimes I would like to be active and on my feet more.</s> |  I can understand that. Do you have any hobbies you like to do in your spare time? |  I feel you. Stretch along the halls\u001b[0m\n",
      "\u001b[34m06/07/2024 04:27:01 - INFO - __main__ - chatbot: your persona: i work as an electrician. i always sleep 8 hours a day. </s>  <s> I really do but sometimes I would like to be active and on my feet more.</s> |  I hear you. I'm a bit of an insomniac myself. |  I feel you. Stretch along the halls\u001b[0m\n",
      "\u001b[34m06/07/2024 04:27:01 - INFO - __main__ - chatbot: I received on-the-job training when i first started</s> |  That's great! How long did it take you to get to the point where you were trained? |  Thats great! How long have you been doing this work? \u001b[0m\n",
      "\u001b[34m06/07/2024 04:27:01 - INFO - __main__ - chatbot: I received on-the-job training when i first started </s> <s> Thats great! How long have you been doing this work?  </s> <s> For a good number of years now.</s> |  What kind of work do you do? I have been doing it for about 10 years.  |  Sounds like it could be a dangerous job at times.\u001b[0m\n",
      "\u001b[34m06/07/2024 04:27:01 - INFO - __main__ - chatbot: For a good number of years now.</s> |  Do you like chatbots? I use them all the time to talk to my friends. |  Sounds like it could be a dangerous job at times.\u001b[0m\n",
      "\u001b[34m06/07/2024 04:27:01 - INFO - __main__ - chatbot: For a good number of years now. </s> <s> Sounds like it could be a dangerous job at times. </s> <s> That it is,especially if you dont take the proper measures</s> |  I'm sure it can be, especially if you don't know what to expect. |  Well you have entered a trade that will always guarantee you some work.\u001b[0m\n",
      "\u001b[34m06/07/2024 04:27:01 - INFO - __main__ - chatbot: That it is,especially if you dont take the proper measures</s> |  What do you mean by that? I don't understand what you are trying to say. |  Well you have entered a trade that will always guarantee you some work.\u001b[0m\n",
      "\u001b[34m06/07/2024 04:27:01 - INFO - __main__ - chatbot: That it is,especially if you dont take the proper measures </s> <s> Well you have entered a trade that will always guarantee you some work. </s> <s> Thats true,especially in this economy</s> |  I have been in the same job for a long time now and it has been great. |  I have a pretty stable job myself, but mostly desk work\u001b[0m\n",
      "\u001b[34m06/07/2024 04:27:01 - INFO - __main__ - chatbot: Thats true,especially in this economy</s> |  Yes, it is.  It's sad that the economy is so bad right now. |  I have a pretty stable job myself, but mostly desk work\u001b[0m\n",
      "\u001b[34m06/07/2024 04:27:05 - INFO - __main__ - printing few sample generations and corresponding labels from eval set\u001b[0m\n",
      "\u001b[34m06/07/2024 04:27:05 - INFO - __main__ - prompt | generated | label\u001b[0m\n",
      "\u001b[34m06/07/2024 04:27:05 - INFO - __main__ - chatbot: your persona: i like rap music. i drive a truck. </s>  <s> I love trucks, too. I take one when I go camping. Do you like fishing or camping </s> <s> Yeah, I love both actually, just went camping recently out in Indiana. </s> <s> Cool. Was it a fun trip?</s> |  Yes, it was a lot of fun. It was nice to get away from the city. |  It was, super peaceful and relaxing.\u001b[0m\n",
      "\u001b[34m06/07/2024 04:27:05 - INFO - __main__ - chatbot: your persona: i like rap music. i drive a truck. </s>  <s> Cool. Was it a fun trip?</s> |  It was a lot of fun. I listened to some rap music on the way there. |  It was, super peaceful and relaxing.\u001b[0m\n",
      "\u001b[34m06/07/2024 04:27:05 - INFO - __main__ - chatbot: your persona: i like rap music. i drive a truck. </s>  <s> Cool. Was it a fun trip? </s> <s> It was, super peaceful and relaxing. </s> <s> It helps to get away from the hustle and noise of the city sometimes.</s> |  Yes it does. I like to listen to rap music when I'm out on the road. |  Exactly, sometimes the city can just be a bit too much.\u001b[0m\n",
      "\u001b[34m06/07/2024 04:27:05 - INFO - __main__ - chatbot: your persona: i like rap music. i drive a truck. </s>  <s> It helps to get away from the hustle and noise of the city sometimes.</s> |  Yes, it does. I listen to a lot of rap music while I drive my truck. |  Exactly, sometimes the city can just be a bit too much.\u001b[0m\n",
      "\u001b[34m06/07/2024 04:27:05 - INFO - __main__ - chatbot: Honestly I have too, what sort of crazy experiences?</s> |  Well, one time I was in a car wreck and I got hit by a drunk driver. |  I had a near death experience after crashing my sports car.\u001b[0m\n",
      "\u001b[34m06/07/2024 04:27:05 - INFO - __main__ - chatbot: Honestly I have too, what sort of crazy experiences? </s> <s> I had a near death experience after crashing my sports car. </s> <s> Wow, that's rough, are you okay now at least?</s> |  Yeah, I'm fine now. It was a long time ago, but it still stings. |  Yeah, fine. I have a habit of driving too fast. Are you a fan of sports cars?\u001b[0m\n",
      "\u001b[34m06/07/2024 04:27:05 - INFO - __main__ - chatbot: Wow, that's rough, are you okay now at least?</s> |  Yeah, I'm fine now. It was a long time ago, but it still stings. |  Yeah, fine. I have a habit of driving too fast. Are you a fan of sports cars?\u001b[0m\n",
      "\u001b[34m06/07/2024 04:27:05 - INFO - __main__ - chatbot: Wow, that's rough, are you okay now at least? </s> <s> Yeah, fine. I have a habit of driving too fast. Are you a fan of sports cars? </s> <s> Yeah, I think they're interesting, definitely prefer my truck though.</s> |  What kind of truck do you have? I'm a big fan of Ford trucks. |  I love trucks, too. I take one when I go camping. Do you like fishing or camping\u001b[0m\n",
      "\u001b[34m06/07/2024 04:27:05 - INFO - __main__ - chatbot: Yeah, I think they're interesting, definitely prefer my truck though.</s> |  What kind of truck do you have? I have a Ford F-Series. |  I love trucks, too. I take one when I go camping. Do you like fishing or camping\u001b[0m\n",
      "\u001b[34m06/07/2024 04:27:05 - INFO - __main__ - chatbot: Yeah, I think they're interesting, definitely prefer my truck though. </s> <s> I love trucks, too. I take one when I go camping. Do you like fishing or camping </s> <s> Yeah, I love both actually, just went camping recently out in Indiana.</s> |  I have never been camping, but I would love to go one day. What kind of camping did you do? |  Cool. Was it a fun trip?\u001b[0m\n",
      "\u001b[34m06/07/2024 04:27:05 - INFO - __main__ - chatbot: Yeah, I love both actually, just went camping recently out in Indiana.</s> |  I have never been camping, but I have always wanted to go. How was it? |  Cool. Was it a fun trip?\u001b[0m\n",
      "\u001b[34m06/07/2024 04:27:05 - INFO - __main__ - chatbot: Yeah, I love both actually, just went camping recently out in Indiana. </s> <s> Cool. Was it a fun trip? </s> <s> It was, super peaceful and relaxing.</s> |  I'm glad you had a good time. What did you do while you were out there? |  It helps to get away from the hustle and noise of the city sometimes.\u001b[0m\n",
      "\u001b[34m06/07/2024 04:27:05 - INFO - __main__ - chatbot: It was, super peaceful and relaxing.</s> |  I love chatting on the phone. It's so relaxing to talk to someone in person. |  It helps to get away from the hustle and noise of the city sometimes.\u001b[0m\n",
      "\u001b[34m06/07/2024 04:27:05 - INFO - __main__ - chatbot: your persona: i like to make cookies. i like to run. </s>  <s> what are screwballs? I dont think i ever heard of that!</s> |  It's a type of cookie. I like to bake them. Do you bake? |  They are toys that came with ice cream treat, I tried to collect.\u001b[0m\n",
      "\u001b[34m06/07/2024 04:27:05 - INFO - __main__ - chatbot: your persona: i like to make cookies. i like to run. </s>  <s> ahhhh. I dont remember those, but one interesting thing is i hated vegetables as a kid and still hate them today!</s> |  I love veggies, especially cookies! What kind of cookies do you like? |  I hear you about vegetables, I personally love cookies. I feel like baking today after take my daily run.\u001b[0m\n",
      "\u001b[34m06/07/2024 04:27:05 - INFO - __main__ - chatbot: your persona: i like to make cookies. i like to run. </s>  <s> I may take a run myself, but am really thinking of going to American Eagle, my favorite store...they have a sale!</s> |  i love american eagle! they have the best deals on clothes and accessories. |  What do you like to purchase there? I like the tee's personaly.\u001b[0m\n",
      "\u001b[34m06/07/2024 04:27:08 - INFO - __main__ - printing few sample generations and corresponding labels from eval set\u001b[0m\n",
      "\u001b[34m06/07/2024 04:27:08 - INFO - __main__ - prompt | generated | label\u001b[0m\n",
      "\u001b[34m06/07/2024 04:27:08 - INFO - __main__ - chatbot: I'm not a great cook. </s> <s> I love to cook...italian and sea foods are my favorite :) </s> <s> Awesome. I love sea food too!  </s> <s> shrimp and pasta is good...seafood with italian...:) </s> <s> Shrimp is the best. Especially with italian.</s> |  Italian cuisine is one of the most popular in the world and I love it! |  yes...maybe i will make that tonight!\u001b[0m\n",
      "\u001b[34m06/07/2024 04:27:08 - INFO - __main__ - chatbot: Awesome. I love sea food too! </s> |  I love seafood too, especially crab and lobster. What is your favorite? |  shrimp and pasta is good...seafood with italian...:)\u001b[0m\n",
      "\u001b[34m06/07/2024 04:27:08 - INFO - __main__ - chatbot: Awesome. I love sea food too!  </s> <s> shrimp and pasta is good...seafood with italian...:) </s> <s> Shrimp is the best. Especially with italian.</s> |  Italian cuisine is one of the most popular in the world.  Do you like it? |  yes...maybe i will make that tonight!\u001b[0m\n",
      "\u001b[34m06/07/2024 04:27:08 - INFO - __main__ - chatbot: Shrimp is the best. Especially with italian.</s> |  I love shrimp too, especially with garlic sauce. Do you like to cook? |  yes...maybe i will make that tonight!\u001b[0m\n",
      "\u001b[34m06/07/2024 04:27:08 - INFO - __main__ - chatbot: your persona: i'm a painter and love to create art. i'm a talented singer and have won several competitions. </s>  <s> My Father played the guitar, but he is having some health problems right now.</s> |  Oh, I'm sorry to hear that. I hope he gets well soon. What kind of health issues? |  I'm sorry to hear that, hopefully he starts feeling better soon. How are you holding up?\u001b[0m\n",
      "\u001b[34m06/07/2024 04:27:08 - INFO - __main__ - chatbot: your persona: i'm a painter and love to create art. i'm a talented singer and have won several competitions. </s>  <s> I am doing ok. Thanks for asking. Playing guitar helps me cope. My father has a cool collection of guitars.</s> |  That's cool. I wish I could play an instrument. What kind of music do you play? |  Nice, any particular songs you normally play?\u001b[0m\n",
      "\u001b[34m06/07/2024 04:27:08 - INFO - __main__ - chatbot: your persona: i'm a painter and love to create art. i'm a talented singer and have won several competitions. </s>  <s> I love to play Jimi Hendrix songs. Are you a fan of 1960's rock? What is your favorite genre?</s> |  I am a big fan of the 60's. My favorite band is the Beatles. |  Of course, I love 60's rock, my favorite has to be classic rock for sure. Zeppelin and The Doors have to be my favorite bands\u001b[0m\n",
      "\u001b[34m06/07/2024 04:27:08 - INFO - __main__ - chatbot: your persona: i'm a painter and love to create art. i'm a talented singer and have won several competitions. </s>  <s> I love the Doors! They have such a unique sound. Do you have a favorite Doors song?</s> |  My favorite song of theirs is \"When I Was Your Man\". What's yours? |  It's a tie between People are strange and Love me two times. What's your favorite?\u001b[0m\n",
      "\u001b[34m06/07/2024 04:27:08 - INFO - __main__ - chatbot: your persona: i'm a painter and love to create art. i'm a talented singer and have won several competitions. </s>  <s> I think my favorite is Love Street. It has such a haunting melody. Have you heard that one?</s> |  No, I haven't. I'll have to check it out. What genre is it? |  Yeah, it's a pretty great song, Jim Morrison was just an amazing songwriter, I aspire to make songs as good as his one day.\u001b[0m\n",
      "\u001b[34m06/07/2024 04:27:08 - INFO - __main__ - chatbot: your persona: i'm a painter and love to create art. i'm a talented singer and have won several competitions. </s>  <s> I wish you the best of luck. Music is a great way to express yourself.</s> |  Thank you so much! I appreciate that. What kind of music do you like? I love all kinds. |  The best way in my opinion. There's just so much that can be said through music that sometimes can't be expressed in words alone\u001b[0m\n",
      "\u001b[34m06/07/2024 04:27:08 - INFO - __main__ - chatbot: I'm sorry to hear that, hopefully he starts feeling better soon. How are you holding up?</s> |  I'm doing well, thank you. It's been a long time since I've seen him. |  I am doing ok. Thanks for asking. Playing guitar helps me cope. My father has a cool collection of guitars.\u001b[0m\n",
      "\u001b[34m06/07/2024 04:27:08 - INFO - __main__ - chatbot: Nice, any particular songs you normally play?</s> |  I play a lot of classical music on the piano.  What about you? |  I love to play Jimi Hendrix songs. Are you a fan of 1960's rock? What is your favorite genre?\u001b[0m\n",
      "\u001b[34m06/07/2024 04:27:08 - INFO - __main__ - chatbot: Of course, I love 60's rock, my favorite has to be classic rock for sure. Zeppelin and The Doors have to be my favorite bands</s> |  I love both of those bands as well. They were formed in 1962. |  I love the Doors! They have such a unique sound. Do you have a favorite Doors song?\u001b[0m\n",
      "\u001b[34m06/07/2024 04:27:08 - INFO - __main__ - chatbot: It's a tie between People are strange and Love me two times. What's your favorite?</s> |  I don't really have a favorite, but I do know that people can be strange sometimes. |  I think my favorite is Love Street. It has such a haunting melody. Have you heard that one?\u001b[0m\n",
      "\u001b[34m06/07/2024 04:27:08 - INFO - __main__ - chatbot: Yeah, it's a pretty great song, Jim Morrison was just an amazing songwriter, I aspire to make songs as good as his one day.</s> |  Do you have a favorite song of his that you would like to sing? I really like \"Love Me Do\". |  I wish you the best of luck. Music is a great way to express yourself.\u001b[0m\n",
      "\u001b[34m06/07/2024 04:27:08 - INFO - __main__ - chatbot: your persona: i am an athlete. i went to the university of north carolina. </s>  <s> To say the least..lol</s> |  What do you do for a living? I play football for the University of North Carolina |  that was embarrassing! ha ha\u001b[0m\n",
      "\u001b[34m06/07/2024 04:27:10 - INFO - __main__ - printing few sample generations and corresponding labels from eval set\u001b[0m\n",
      "\u001b[34m06/07/2024 04:27:10 - INFO - __main__ - prompt | generated | label\u001b[0m\n",
      "\u001b[34m06/07/2024 04:27:10 - INFO - __main__ - chatbot: your persona: i already have 3 children. i am 26 years old. </s>  <s> and expensive I am sure!  My daughter took care of most of the grand kids expenses ;)</s> |  How old is your daughter? I'm sure she's a great parent. I don't have kids yet. |  Definitely, I don't know how I'd manage if I didn't have my husband's help. Sounds like she loves you very much\u001b[0m\n",
      "\u001b[34m06/07/2024 04:27:10 - INFO - __main__ - chatbot: your persona: i already have 3 children. i am 26 years old. </s>  <s> yes, we went to the bahamas too...for my other daughters wedding...been hitting those HOT places lately! lol</s> |  That sounds like a lot of fun! How many kids do you have? I have 3. |  Yeah, you must have spent a fortune on sunscreen lol\u001b[0m\n",
      "\u001b[34m06/07/2024 04:27:10 - INFO - __main__ - chatbot: your persona: i already have 3 children. i am 26 years old. </s>  <s> You beetter believe it, at least no one got burnt.</s> |  I'm not sure what you mean by that, but I'm glad no one was hurt. |  That's good, if you don't shell out on sunscreen your wallet will feel it later when you have to shop for aloe\u001b[0m\n",
      "\u001b[34m06/07/2024 04:27:10 - INFO - __main__ - chatbot: your persona: i already have 3 children. i am 26 years old. </s>  <s> thats true! do you live in a warm climate</s> |  Yes, I live in Florida. It is hot and humid here. How about you? |  Yeah, I live in southern California and it can get a bit hot sometimes\u001b[0m\n",
      "\u001b[34m06/07/2024 04:27:10 - INFO - __main__ - chatbot: Glad you had a good time though, I haven't gotten around to taking my kids there yet, I hear there's a lot to do though</s> |  Yeah, it was a lot of fun. I hope you get to take your kids soon. |  yes there is! something for all ages.  I love to travel :)\u001b[0m\n",
      "\u001b[34m06/07/2024 04:27:10 - INFO - __main__ - chatbot: Me too! I used to travel all the time but it's gotten a bit harder to do with three kids</s> |  I know what you mean. It's hard to find the time to do things like that. |  and expensive I am sure!  My daughter took care of most of the grand kids expenses ;)\u001b[0m\n",
      "\u001b[34m06/07/2024 04:27:10 - INFO - __main__ - chatbot: Definitely, I don't know how I'd manage if I didn't have my husband's help. Sounds like she loves you very much</s> |  Yes, she does.  I am so grateful to have her in my life. |  yes, we went to the bahamas too...for my other daughters wedding...been hitting those HOT places lately! lol\u001b[0m\n",
      "\u001b[34m06/07/2024 04:27:10 - INFO - __main__ - chatbot: Yeah, you must have spent a fortune on sunscreen lol</s> |  I did spend a lot of money, but it was worth it in the end. I had a great time. |  You beetter believe it, at least no one got burnt.\u001b[0m\n",
      "\u001b[34m06/07/2024 04:27:10 - INFO - __main__ - chatbot: Yeah, you must have spent a fortune on sunscreen lol </s> <s> You beetter believe it, at least no one got burnt. </s> <s> That's good, if you don't shell out on sunscreen your wallet will feel it later when you have to shop for aloe</s> |  That is a good tip, I will keep that in mind next time I go to the beach. |  thats true! do you live in a warm climate\u001b[0m\n",
      "\u001b[34m06/07/2024 04:27:10 - INFO - __main__ - chatbot: That's good, if you don't shell out on sunscreen your wallet will feel it later when you have to shop for aloe</s> |  That's a good point. I'll have to keep that in mind next time I go out. |  thats true! do you live in a warm climate\u001b[0m\n",
      "\u001b[34m06/07/2024 04:27:10 - INFO - __main__ - chatbot: your persona: i live in portland, oregon. i like to make my own coffee. </s>  <s> I don't think. Possitive thinking and fingers crossed. </s> |  I live in Portland, Oregon, home of the coffee beans. |  yes I will keep my fingers crossed for you.  are you nervous for court?\u001b[0m\n",
      "\u001b[34m06/07/2024 04:27:10 - INFO - __main__ - chatbot: your persona: i live in portland, oregon. i like to make my own coffee. </s>  <s> Court scares me to death. What do you do to relax before a stressful thing. </s> |  I like to go for long walks on the beach. It helps me clear my head. |  I try my best to keep busy so I don't think so much about what's stressing me out\u001b[0m\n",
      "\u001b[34m06/07/2024 04:27:10 - INFO - __main__ - chatbot: your persona: i live in portland, oregon. i like to make my own coffee. </s>  <s> I'm a huge book reader. It's about the only thing that can take my mind off things. </s> |  What kind of books do you like to read? I'm more of a movie person myself. |  I love reading as well, what are you reading right now?\u001b[0m\n",
      "\u001b[34m06/07/2024 04:27:10 - INFO - __main__ - chatbot: your persona: i live in portland, oregon. i like to make my own coffee. </s>  <s> I'm reading about 3 at a time right now. I'm into Sci-fi, fantasy and distopian. You?</s> |  I like sci fi and fantasy as well. Do you have any favorite authors? |  My favorites are biographies and mysteries, but I will read almost anything if it is recommended to me\u001b[0m\n",
      "\u001b[34m06/07/2024 04:27:10 - INFO - __main__ - chatbot: your persona: i live in portland, oregon. i like to make my own coffee. </s>  <s> Im reading a Sci-Fi right now Named \"Dark Space\" it pretty good. I have different books on my Ipad and my Iphone. I also use a kindle. </s> |  I like sci-fi as well. Do you have any favorite authors? |  I will have to check it out, I don't use e-readers, I'm old fashioned and prefer reading physical books myself.\u001b[0m\n",
      "\u001b[34m06/07/2024 04:27:10 - INFO - __main__ - chatbot: your persona: i live in portland, oregon. i like to make my own coffee. </s>  <s> Over the years I have moved so much I've lost most of my books so I definitly prefer my ebooks. I won't lose them and can read them anywhere.</s> |  That's a good idea. I don't have a lot of time to read since I work so much. |  that's a good point, and it's much lighter to carry around!  but the screen hurts my eyes after too long\u001b[0m\n",
      "\u001b[34m06/07/2024 04:27:13 - INFO - __main__ - printing few sample generations and corresponding labels from eval set\u001b[0m\n",
      "\u001b[34m06/07/2024 04:27:13 - INFO - __main__ - prompt | generated | label\u001b[0m\n",
      "\u001b[34m06/07/2024 04:27:13 - INFO - __main__ - chatbot: your persona: one day i played the lottery. i will never punch a clock again. </s>  <s> That sounds like an awesome job! </s> |  It was.  I won $250,000.  That's a lot of money. |  it is..i love the freedoms :)\u001b[0m\n",
      "\u001b[34m06/07/2024 04:27:13 - INFO - __main__ - chatbot: your persona: one day i played the lottery. i will never punch a clock again. </s>  <s> That sounds like an awesome job!  </s> <s> it is..i love the freedoms :) </s> <s> Can you work from home?</s> |  I can, but I don't have a lot of time to do it. I work in IT. |  Yes i do! just need an internet connection wth good speed and good computer\u001b[0m\n",
      "\u001b[34m06/07/2024 04:27:13 - INFO - __main__ - chatbot: your persona: one day i played the lottery. i will never punch a clock again. </s>  <s> Can you work from home?</s> |  I can, but it's not the same as going out and meeting people. It's a lot of fun. |  Yes i do! just need an internet connection wth good speed and good computer\u001b[0m\n",
      "\u001b[34m06/07/2024 04:27:13 - INFO - __main__ - chatbot: I agree, that's why I favor smaller towns opposed to big cities. Just not my thing.</s> |  I live in a small town and I love it. It's so quiet and peaceful. |  I don't like huge cities, too much traffic.\u001b[0m\n",
      "\u001b[34m06/07/2024 04:27:13 - INFO - __main__ - chatbot: I agree, that's why I favor smaller towns opposed to big cities. Just not my thing. </s> <s> I don't like huge cities, too much traffic. </s> <s> i used to sit in 2 hours of traffic daily. no longer is that my problem</s> |  I used to live in a big city, but now I live in the suburbs. |  Where was that?\u001b[0m\n",
      "\u001b[34m06/07/2024 04:27:13 - INFO - __main__ - chatbot: i used to sit in 2 hours of traffic daily. no longer is that my problem</s> |  Oh wow, that's a long time to be stuck in traffic. How did you get out of it? |  Where was that?\u001b[0m\n",
      "\u001b[34m06/07/2024 04:27:13 - INFO - __main__ - chatbot: i used to sit in 2 hours of traffic daily. no longer is that my problem </s> <s> Where was that? </s> <s> new york  but i recently bought a lottery ticket.</s> |  That's great! I hope you win a lot of money. What will you do with the money? |  I have never been to New York but would like to visit. Did you win the lottery ticket?\u001b[0m\n",
      "\u001b[34m06/07/2024 04:27:13 - INFO - __main__ - chatbot: new york  but i recently bought a lottery ticket.</s> |  That's awesome! How much did you win? I've never won anything in the lottery. |  I have never been to New York but would like to visit. Did you win the lottery ticket?\u001b[0m\n",
      "\u001b[34m06/07/2024 04:27:13 - INFO - __main__ - chatbot: new york  but i recently bought a lottery ticket. </s> <s> I have never been to New York but would like to visit. Did you win the lottery ticket? </s> <s> Yes, enough that i work for myself now!  No more checking in and no more traffic hassles!</s> |  That's great! I would love to visit New York one day. Have you ever been? |  That sounds like an awesome job! \u001b[0m\n",
      "\u001b[34m06/07/2024 04:27:13 - INFO - __main__ - chatbot: Yes, enough that i work for myself now!  No more checking in and no more traffic hassles!</s> |  What do you do for a living, if you don't mind me asking? I work in IT. |  That sounds like an awesome job!\u001b[0m\n",
      "\u001b[34m06/07/2024 04:27:13 - INFO - __main__ - chatbot: Yes, enough that i work for myself now!  No more checking in and no more traffic hassles! </s> <s> That sounds like an awesome job!  </s> <s> it is..i love the freedoms :)</s> |  I bet it is.  I would love to be able to work from home one day. |  Can you work from home?\u001b[0m\n",
      "\u001b[34m06/07/2024 04:27:13 - INFO - __main__ - chatbot: it is..i love the freedoms :)</s> |  I do too.  It's nice to be able to do what I want without worrying about money. |  Can you work from home?\u001b[0m\n",
      "\u001b[34m06/07/2024 04:27:13 - INFO - __main__ - chatbot: your persona: i am a software engineer. my favorite seafood in lobster. </s>  <s> and i work as an accountant</s> |  I love lobster, it is one of my favorite foods. Do you like lobster? |  how do you enjoy working as an accountant?\u001b[0m\n",
      "\u001b[34m06/07/2024 04:27:13 - INFO - __main__ - chatbot: your persona: i am a software engineer. my favorite seafood in lobster. </s>  <s> and i work as an accountant </s> <s> how do you enjoy working as an accountant? </s> <s> i do enjoy dealing with money,lol!</s> |  I bet you do.  I'm an engineer so I don't know much about accounting. |  well you and I have that in common! however I am not overly financially literate, I don't think I could do that job\u001b[0m\n",
      "\u001b[34m06/07/2024 04:27:13 - INFO - __main__ - chatbot: your persona: i am a software engineer. my favorite seafood in lobster. </s>  <s> i do enjoy dealing with money,lol!</s> |  I do as well.  I work in IT.  What do you do for a living? |  well you and I have that in common! however I am not overly financially literate, I don't think I could do that job\u001b[0m\n",
      "\u001b[34m06/07/2024 04:27:13 - INFO - __main__ - chatbot: your persona: i am a software engineer. my favorite seafood in lobster. </s>  <s> why? though you need to be highly literate to do accounting it needs a lot of operations</s> |  I love lobster, it is one of my favorite foods. Do you like lobster? |  I have heard sometimes it can be boring\u001b[0m\n",
      "\u001b[34m06/07/2024 04:27:22 - INFO - __main__ - {'bleu': 1.7961879248721508}\u001b[0m\n",
      "\u001b[34mevaluation completed\u001b[0m\n",
      "\u001b[34m06/07/2024 04:27:22 - INFO - __main__ - Epoch 0 evaluation took 24.033387422561646 seconds\u001b[0m\n",
      "\u001b[34mConfiguration saved in /opt/ml/model/config.json\u001b[0m\n",
      "\u001b[34mModel weights saved in /opt/ml/model/pytorch_model.bin\u001b[0m\n",
      "\u001b[34mtokenizer config file saved in /opt/ml/model/tokenizer_config.json\u001b[0m\n",
      "\u001b[34mSpecial tokens file saved in /opt/ml/model/special_tokens_map.json\u001b[0m\n",
      "\u001b[34m100%|██████████| 79/79 [00:53<00:00,  1.48it/s]\u001b[0m\n",
      "\u001b[34m2024-06-07 04:27:28,376 sagemaker-training-toolkit INFO     Waiting for the process to finish and give a return code.\u001b[0m\n",
      "\u001b[34m2024-06-07 04:27:28,376 sagemaker-training-toolkit INFO     Done waiting for a return code. Received 0 from exiting process.\u001b[0m\n",
      "\u001b[34m2024-06-07 04:27:28,377 sagemaker-training-toolkit INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2024-06-07 04:28:03 Uploading - Uploading generated training model\n",
      "2024-06-07 04:28:03 Completed - Resource retained for reuse\n",
      "Training seconds: 174\n",
      "Billable seconds: 174\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "pt_estimator = PyTorch(\n",
    "    base_job_name=\"accelerate-launcher-shell\",\n",
    "    source_dir=\"seq2seq\", # folder with all the dependencies as source directory\n",
    "    entry_point=\"launch_shell.sh\", # shell script as entrypoint\n",
    "    role=role,\n",
    "    py_version=\"py310\",\n",
    "    framework_version=\"2.0.1\",\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.p3.16xlarge\",\n",
    "    keep_alive_period_in_seconds=3600\n",
    "\n",
    ")\n",
    "pt_estimator.fit() #since I am pulling the data from the python script I did not pass an s3 uri with my dataset in teh fit method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefc94c3-3e2a-4f24-a122-99281e07cae5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "availableInstances": [
   {
    "_defaultOrder": 0,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.t3.medium",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 1,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.t3.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 2,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.t3.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 3,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.t3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 4,
    "_isFastLaunch": true,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 5,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 6,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 7,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 8,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 9,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 10,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 11,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 12,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.m5d.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 13,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.m5d.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 14,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.m5d.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 15,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.m5d.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 16,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.m5d.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 17,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.m5d.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 18,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.m5d.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 19,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.m5d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 20,
    "_isFastLaunch": false,
    "category": "General purpose",
    "gpuNum": 0,
    "hideHardwareSpecs": true,
    "memoryGiB": 0,
    "name": "ml.geospatial.interactive",
    "supportedImageNames": [
     "sagemaker-geospatial-v1-0"
    ],
    "vcpuNum": 0
   },
   {
    "_defaultOrder": 21,
    "_isFastLaunch": true,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 4,
    "name": "ml.c5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 22,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 8,
    "name": "ml.c5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 23,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.c5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 24,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.c5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 25,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 72,
    "name": "ml.c5.9xlarge",
    "vcpuNum": 36
   },
   {
    "_defaultOrder": 26,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 96,
    "name": "ml.c5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 27,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 144,
    "name": "ml.c5.18xlarge",
    "vcpuNum": 72
   },
   {
    "_defaultOrder": 28,
    "_isFastLaunch": false,
    "category": "Compute optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.c5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 29,
    "_isFastLaunch": true,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g4dn.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 30,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g4dn.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 31,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g4dn.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 32,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g4dn.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 33,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g4dn.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 34,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g4dn.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 35,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 61,
    "name": "ml.p3.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 36,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 244,
    "name": "ml.p3.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 37,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 488,
    "name": "ml.p3.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 38,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.p3dn.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 39,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.r5.large",
    "vcpuNum": 2
   },
   {
    "_defaultOrder": 40,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.r5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 41,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.r5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 42,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.r5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 43,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.r5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 44,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.r5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 45,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.r5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 46,
    "_isFastLaunch": false,
    "category": "Memory Optimized",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.r5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 47,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 16,
    "name": "ml.g5.xlarge",
    "vcpuNum": 4
   },
   {
    "_defaultOrder": 48,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.g5.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 49,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 64,
    "name": "ml.g5.4xlarge",
    "vcpuNum": 16
   },
   {
    "_defaultOrder": 50,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 128,
    "name": "ml.g5.8xlarge",
    "vcpuNum": 32
   },
   {
    "_defaultOrder": 51,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 1,
    "hideHardwareSpecs": false,
    "memoryGiB": 256,
    "name": "ml.g5.16xlarge",
    "vcpuNum": 64
   },
   {
    "_defaultOrder": 52,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 192,
    "name": "ml.g5.12xlarge",
    "vcpuNum": 48
   },
   {
    "_defaultOrder": 53,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 4,
    "hideHardwareSpecs": false,
    "memoryGiB": 384,
    "name": "ml.g5.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 54,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 768,
    "name": "ml.g5.48xlarge",
    "vcpuNum": 192
   },
   {
    "_defaultOrder": 55,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4d.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 56,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 8,
    "hideHardwareSpecs": false,
    "memoryGiB": 1152,
    "name": "ml.p4de.24xlarge",
    "vcpuNum": 96
   },
   {
    "_defaultOrder": 57,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 32,
    "name": "ml.trn1.2xlarge",
    "vcpuNum": 8
   },
   {
    "_defaultOrder": 58,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1.32xlarge",
    "vcpuNum": 128
   },
   {
    "_defaultOrder": 59,
    "_isFastLaunch": false,
    "category": "Accelerated computing",
    "gpuNum": 0,
    "hideHardwareSpecs": false,
    "memoryGiB": 512,
    "name": "ml.trn1n.32xlarge",
    "vcpuNum": 128
   }
  ],
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science 3.0)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/sagemaker-data-science-310-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
